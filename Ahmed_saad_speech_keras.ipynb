{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_GP2020N.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "teB_Uoq4kR04",
        "IBaqEjXvoozh",
        "JFiUkUtT6QqW",
        "aviY2rqhdWYR",
        "34fb8LhiBGSD",
        "loDjyAOcyCAB",
        "hbMZHWDjwNqQ",
        "yKrDgXtTBXn4",
        "w6nh1lniWCIR",
        "WbTiUmENPJw7",
        "1e0tAAlJhGkt",
        "YImpavP9kina",
        "eToUFWHw0hAP",
        "_LhueYgS7gy6",
        "hw3zmQ8vAAFc",
        "qOxCWY8GBTkw"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvPqtIgH5Tft"
      },
      "source": [
        "# **Downloading data from kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DH6kQdr5gg-"
      },
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsM_847Z5qKL"
      },
      "source": [
        "%cd /root\n",
        "!mkdir .kaggle\n",
        "!mv /content/kaggle.json /root/.kaggle\n",
        "%cd /root/.kaggle\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIY-tO1d5zKs"
      },
      "source": [
        "!kaggle competitions download -c tensorflow-speech-recognition-challenge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-w6oSZR55rM"
      },
      "source": [
        "%cd /root/.kaggle\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLslmPL_6RPU"
      },
      "source": [
        "!mkdir train\n",
        "!mkdir test\n",
        "!mkdir sample_submission\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmGzow2a6spr"
      },
      "source": [
        "!mv /root/.kaggle/train.7z /root/.kaggle/train\n",
        "!mv /root/.kaggle/test.7z /root/.kaggle/test\n",
        "!mv /root/.kaggle/sample_submission.7z /root/.kaggle/sample_submission\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDLgc7-o-VN7"
      },
      "source": [
        "# **Google Drive mount**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NxOTJ4J-kpY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQYg8gKkxPwy"
      },
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkWqjCH8w3SH"
      },
      "source": [
        "# **Unzipping the train dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjQKLpUiw_jN"
      },
      "source": [
        "%cd /root/.kaggle/train\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY4NhW4xybKn"
      },
      "source": [
        "!7za x train.7z\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGsE-J3C1a00"
      },
      "source": [
        "%cd /root/.kaggle/train\n",
        "!rm train.7z\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDB7thj8yl3l"
      },
      "source": [
        "#!cp -a /root/.kaggle/train/train/. /content/drive/My\\ Drive/NLP_Dataset/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-21B9pfp7ZVm"
      },
      "source": [
        "#%cd /content/drive/My\\ Drive/NLP_Dataset/audio\n",
        "#!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teB_Uoq4kR04"
      },
      "source": [
        "# **unique IDs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPZD5Yrej8hM"
      },
      "source": [
        "%cd /root/.kaggle/train/train/\n",
        "!ls\n",
        "testing_id = open(\"testing_list.txt\").read().splitlines()\n",
        "validation_id = open(\"validation_list.txt\").read().splitlines()\n",
        "#'bed/b1f8326d_nohash_0.wav' in validation_list\n",
        "print('len of test set is ' + str(len(testing_id)) )\n",
        "print('len of validation set is ' + str(len(validation_id)) )\n",
        "print(testing_id[0].split('_',1)[0].split('/')[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNzigJNcn0cK"
      },
      "source": [
        "import os\n",
        "from os.path import isdir, join\n",
        "train_audio_path = '/root/.kaggle/train/train/audio'\n",
        "dirs=[]\n",
        "for f in os.listdir(train_audio_path):\n",
        "  if isdir(join(train_audio_path, f)):\n",
        "    dirs.append(f)\n",
        "dirs.sort()\n",
        "print('Number of labels: ' + str(len(dirs)))\n",
        "print(dirs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYQOWa7koIxb"
      },
      "source": [
        "# all samples duration should be 1 sec\n",
        "# adding the zero padding\n",
        "import numpy as np\n",
        "train_id = []\n",
        "test_id = []\n",
        "valid_id = []\n",
        "\n",
        "\n",
        "\n",
        "for direct in dirs:\n",
        "  if (direct == '_background_noise_'):\n",
        "    continue\n",
        "  waves = [f for f in os.listdir(join(train_audio_path, direct)) if f.endswith('.wav')]\n",
        "  print(direct)\n",
        "  #print(waves[0].split('_')[0])\n",
        "  #break\n",
        "  for wav in waves:\n",
        "      #sound_file = join( join(train_audio_path, direct),wav)\n",
        "      #samples, sample_rate = librosa.core.load(sound_file,sr=None)\n",
        "      #sample_rate, samples = wavfile.read(join( join(train_audio_path, direct),wav) )\n",
        "      #print(join( join(train_audio_path, direct),wav))\n",
        "      #break\n",
        "      #if samples.shape[0] < sample_rate:\n",
        "          #zero_padding = sample_rate - samples.shape[0]\n",
        "          # zero padding from the end of the signal\n",
        "          #samples = np.pad(samples, (0,zero_padding), 'constant', constant_values=(0,0))\n",
        "      # Handling the unknown class\n",
        "      #mfcc = logfbank(samples,sample_rate,nfilt=34)\n",
        "      #if (direct == 'unknown'):\n",
        "        #unknown.append(samples)\n",
        "        #unknown_mfcc.append(mfcc)\n",
        "        #labels_unknown.append(direct)\n",
        "        #continue\n",
        "      # adding the wav to its list\n",
        "      sample_id = join(direct, wav)\n",
        "      #if sample_id in silence_id:\n",
        "        #continue\n",
        "      if sample_id in testing_id :\n",
        "        # add the sample to test set\n",
        "        test_id.append(wav.split('_')[0])\n",
        "        #test_mfcc.append(mfcc)\n",
        "        #labels_test.append(direct)\n",
        "      elif sample_id in validation_id :\n",
        "        # add the sample to the validation set\n",
        "        valid_id.append(wav.split('_')[0])\n",
        "      else:\n",
        "        # add the sample to the train set\n",
        "        train_id.append(wav.split('_')[0])\n",
        "\n",
        "        #break\n",
        "      #break\n",
        "      \n",
        "      \n",
        "\n",
        "  #break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mJ-Tdcepn2g"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a-8TxOJqdD7"
      },
      "source": [
        "train_id = np.array(train_id)\n",
        "test_id = np.array(test_id)\n",
        "valid_id = np.array(valid_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npQFPZoZquFm"
      },
      "source": [
        "train_id_unique = np.unique(train_id)\n",
        "test_id_unique = np.unique(test_id)\n",
        "valid_id_unique = np.unique(valid_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0fRPdvhsEfU"
      },
      "source": [
        "train_id_unique[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKWw573lrHk3"
      },
      "source": [
        "for i in range(valid_id_unique.shape[0]):\n",
        "  if valid_id_unique[i] in train_id_unique:\n",
        "    print('hello')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coAx2PpAF5PH"
      },
      "source": [
        "# **Handling the unknown class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpu5CLUoF5dj"
      },
      "source": [
        "%cd /root/.kaggle/train/train/audio\n",
        "!mkdir unknown\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STcDdvQ0IBdP"
      },
      "source": [
        "!cp -a /content/drive/My\\ Drive/NLP_Dataset/unknown/. /root/.kaggle/train/train/audio/unknown/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up3WxYMEJ59F"
      },
      "source": [
        "%cd /root/.kaggle/train/train/audio/unknown/\n",
        "!ls\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBaqEjXvoozh"
      },
      "source": [
        "# **Unzipping the test dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zuyZLjK85FB"
      },
      "source": [
        "%cd /root/.kaggle/test\n",
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgb45KvxGKys"
      },
      "source": [
        "!7za x test.7z  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aduyT3BV4QU"
      },
      "source": [
        "!ls\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnnAvmWJz0v-"
      },
      "source": [
        "!rm test.7z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxi2I-t77cm6"
      },
      "source": [
        "!cp -a  /content/drive/My\\ Drive/NLP_Dataset/codes/submission.txt /root/.kaggle/test/."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E5AVVWBRprT"
      },
      "source": [
        "%cd /root/.kaggle/test/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx9bJlf_7zMX"
      },
      "source": [
        "submission_set = open(\"submission.txt\").read().splitlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OErMhGk_8xs0"
      },
      "source": [
        "del submission_set[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0OBD4NP94LG"
      },
      "source": [
        "submission_set[1].split(',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkIBCyvIRu5l"
      },
      "source": [
        "#!cp -a /root/.kaggle/test/test/. /content/drive/My\\ Drive/NLP_Dataset/test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uedXhAkQSetN"
      },
      "source": [
        "#%cd /content/drive/My\\ Drive/NLP_Dataset/\n",
        "#!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFiUkUtT6QqW"
      },
      "source": [
        "# **Copying the dataset from drive to th VM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKjYr4rM6l-z"
      },
      "source": [
        "%cd /content/\n",
        "!mkdir train_data\n",
        "!cp -a  /content/drive/My\\ Drive/NLP_Dataset/audio/. /content/train_data/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guD6uDzdOOXK"
      },
      "source": [
        "# **Exploring the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w66vHIcOTNx"
      },
      "source": [
        "#%cd /content/drive/My\\ Drive/NLP_Dataset/audio/bed\n",
        "#!ls\n",
        "#!cp -a /content/drive/My\\ Drive/NLP_Dataset/audio/bed/4c4d2526_nohash_0.wav /content/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iJfQNr4OWbv"
      },
      "source": [
        "from scipy.io import wavfile\n",
        "#sound_file = '/content/drive/My Drive/NLP_Dataset/audio/bed/4c4d2526_nohash_0.wav'\n",
        "sound_file = '/root/.kaggle/train/train/audio/bed/4c4d2526_nohash_0.wav'\n",
        "fs, data = wavfile.read(sound_file)\n",
        "print('the number of samples are '+ str(data.shape[0]) + '\\n the sampling frequency is '+ str(fs))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvOtqaelRpd5"
      },
      "source": [
        "pip install python_speech_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftAg9IKQRiyt"
      },
      "source": [
        "from python_speech_features import mfcc\n",
        "from python_speech_features import logfbank"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5hbtVt0RwCC"
      },
      "source": [
        "mfcc_feat = mfcc(data,fs)\n",
        "fbank_feat = logfbank(data,fs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzCb1zW9R4Bh"
      },
      "source": [
        "mfcc_feat.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cedOOM77IGwQ"
      },
      "source": [
        "fbank_feat.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boxj9BxlHxW9"
      },
      "source": [
        "mfcc_feat[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08oxhR6iH2Um"
      },
      "source": [
        "fbank_feat[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SodexGbOrvH"
      },
      "source": [
        "from IPython.display import Audio\n",
        "Audio(data,rate=fs,autoplay=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zepOGF7zZ6Ic"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpHpFypAvbrr"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/NLP_Dataset/codes\n",
        "from soundplot import plotFreq, plotTime\n",
        "plotFreq(data, fs, 'sound in frequency domain')\n",
        "plotTime(data, fs, 'sound in time domain')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOO8IEDLxZfM"
      },
      "source": [
        "# investigating the number of labels\n",
        "import os\n",
        "from os.path import isdir, join\n",
        "train_audio_path = '/root/.kaggle/train/train/audio'\n",
        "dirs=[]\n",
        "for f in os.listdir(train_audio_path):\n",
        "  if isdir(join(train_audio_path, f)):\n",
        "    dirs.append(f)\n",
        "dirs.sort()\n",
        "print('Number of labels: ' + str(len(dirs)))\n",
        "print(dirs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UMdRD3bfNpk"
      },
      "source": [
        "# investigating the number of samples of each label\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "\n",
        "number_of_recordings = []\n",
        "for direct in dirs:\n",
        "    waves = [f for f in os.listdir(join(train_audio_path, direct)) if f.endswith('.wav')]\n",
        "    number_of_recordings.append(len(waves))\n",
        "\n",
        "# Plot\n",
        "data = [go.Histogram(x=dirs, y=number_of_recordings)]\n",
        "trace = go.Bar(\n",
        "    x=dirs,\n",
        "    y=number_of_recordings,\n",
        ")\n",
        "layout = go.Layout(\n",
        "    title='Number of recordings in given label',\n",
        "    xaxis = dict(title='Words'),\n",
        "    yaxis = dict(title='Number of recordings')\n",
        ")\n",
        "py.iplot(go.Figure(data=[trace], layout=layout))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxb5vBNUif5B"
      },
      "source": [
        "%cd /root/.kaggle/train/train/\n",
        "!ls\n",
        "testing_id = open(\"testing_list.txt\").read().splitlines()\n",
        "validation_id = open(\"validation_list.txt\").read().splitlines()\n",
        "#'bed/b1f8326d_nohash_0.wav' in validation_list\n",
        "print('len of test set is ' + str(len(testing_id)) )\n",
        "print('len of validation set is ' + str(len(validation_id)) )\n",
        "print(testing_id[0].split('_',1)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2loyhU1b9qq"
      },
      "source": [
        "from scipy.io import wavfile\n",
        "import librosa\n",
        "sound_file_librose = '/content/drive/My Drive/NLP_Dataset/audio/bed/4c4d2526_nohash_0.wav'\n",
        "sound_file = '/root/.kaggle/train/train/audio/bed/4c4d2526_nohash_0.wav'\n",
        "fs, data = wavfile.read(sound_file)\n",
        "samples,frequency = librosa.load(sound_file_librose,sr=None)\n",
        "print('the number of samples are '+ str(data.shape[0]) + '\\n the sampling frequency is '+ str(fs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRUqEqmFcSui"
      },
      "source": [
        "samples == data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9lEfHj2uDEA"
      },
      "source": [
        "see = librosa.util.normalize(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uA6Mi0huMz-"
      },
      "source": [
        "type(see[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7nlNjUEdEHW"
      },
      "source": [
        "type(data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aviY2rqhdWYR"
      },
      "source": [
        "# **Check the singularity of IDs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eib8wt10dgyN"
      },
      "source": [
        "samples_id = []\n",
        "train_id = []\n",
        "for direct in dirs:\n",
        "  if (direct == '_background_noise_'):\n",
        "    continue\n",
        "  waves = [f for f in os.listdir(join(train_audio_path, direct)) if f.endswith('.wav')]\n",
        "  for wav in waves:\n",
        "    sampleId = join(direct, wav)\n",
        "    if sampleId in testing_id :\n",
        "      a = 0\n",
        "    elif sampleId in validation_id :\n",
        "      a=0\n",
        "    else:\n",
        "      # add the sample to the train set\n",
        "      train_id.append(sampleId.split('_',1)[0])\n",
        "    sampleId = sampleId.split('_',1)[0]\n",
        "    samples_id.append(sampleId)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhejWtm-uI68"
      },
      "source": [
        "samples_idS = set(samples_id)\n",
        "print(len(samples_idS))\n",
        "print(len(samples_id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RyKHoDbixRo"
      },
      "source": [
        "def common_member(a, b): \n",
        "    a_set = set(a) \n",
        "    b_set = set(b) \n",
        "    if (a_set & b_set): \n",
        "        return True \n",
        "    else: \n",
        "        return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfJsmHehsz8E"
      },
      "source": [
        "testing_idN = []\n",
        "validation_idN = []\n",
        "for x in testing_id:\n",
        "  testing_idN.append(x.split('_',1)[0])\n",
        "\n",
        "for x in validation_id:\n",
        "  validation_idN.append(x.split('_',1)[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X78zwtSuunfa"
      },
      "source": [
        "testing_idNS = set(testing_idN)\n",
        "print(len(testing_idNS))\n",
        "print(len(testing_idN))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjgwoKTuuzUZ"
      },
      "source": [
        "validation_idNS = set(validation_idN)\n",
        "print(len(validation_idNS))\n",
        "print(len(validation_idN))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CERJhQFzvEnq"
      },
      "source": [
        "common_member(testing_idNS, validation_idNS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNeK1rAqwQVd"
      },
      "source": [
        "train_id\n",
        "train_idS = set(train_id)\n",
        "print(len(train_idS))\n",
        "print(len(train_id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXBYquBLwdxh"
      },
      "source": [
        "common_member(testing_idNS, train_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivl7miDGEdk0"
      },
      "source": [
        "# **Silence Class generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9EBEUL7wc0c"
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUV02vEpdntE"
      },
      "source": [
        "# Noise reading\n",
        "from scipy.io import wavfile\n",
        "noise = []\n",
        "for direct in dirs:\n",
        "  if (direct == '_background_noise_'):\n",
        "    waves = [f for f in os.listdir(join(train_audio_path, direct)) if f.endswith('.wav')]\n",
        "    for wav in waves:\n",
        "        sound_file = join( join(train_audio_path, direct),wav)\n",
        "        #samples, sample_rate = librosa.core.load(sound_file,sr=None)\n",
        "        sample_rate, samples = wavfile.read(join( join(train_audio_path, direct),wav) )\n",
        "        print(str(int(np.floor(samples.shape[0]/sample_rate))))\n",
        "        chunks = int(np.floor((samples.shape[0])/(sample_rate)))\n",
        "        samples = samples[:chunks*sample_rate]\n",
        "        samples = samples.reshape((chunks,sample_rate))\n",
        "        for sample in samples:\n",
        "          noise.append(sample)\n",
        "        #print(join( join(train_audio_path, direct),wav))\n",
        "        #break\n",
        "  \n",
        "#print('Number of recordings shorter than 1 second: ' + str(num_of_shorter))\n",
        "#print('Number of recordings longer than 1 second: ' + str(num_of_longer))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo5fJNwHzvev"
      },
      "source": [
        "noise = np.asarray(noise)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ6QM6zLz_6-"
      },
      "source": [
        "noise.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp_wj3gYSMi8"
      },
      "source": [
        "from IPython.display import Audio\n",
        "Audio(noise[310],rate=sample_rate,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwrlyD79j_th"
      },
      "source": [
        "#silence,voice = silenceRemoval(noise[0], sample_rate,mode = 2, chunk = 10)\n",
        "#percentage = voice/(silence+voice)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4JkgPirj_MZ"
      },
      "source": [
        "#percentage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_ww3NikkBO2"
      },
      "source": [
        "import random\n",
        "def noiseMixer(wav1,wav2):\n",
        "  percentage = random.uniform(0,1)\n",
        "  return (percentage * wav1 + (1-percentage) * wav2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGrgkcmCk52h"
      },
      "source": [
        "result = noiseMixer(noise[0],noise[150])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWFpFZUSmm6r"
      },
      "source": [
        "Audio(result,rate=sample_rate,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jp8RQ-ulX1L"
      },
      "source": [
        "def generateSilenceClass(noise,no_of_samples):\n",
        "  silence = []\n",
        "  for i in range(no_of_samples):\n",
        "    index1 = random.randrange(0,noise.shape[0])\n",
        "    index2 = random.randrange(0,noise.shape[0])\n",
        "    result = noiseMixer(noise[index1],noise[index2])\n",
        "    silence.append(result)\n",
        "\n",
        "  silence = np.asarray(silence)\n",
        "  return silence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENYrJ4a1nIxh"
      },
      "source": [
        "silence = generateSilenceClass(noise,34000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kr6cnKBnCbZ"
      },
      "source": [
        "Audio(silence[469],rate=sample_rate,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWgsCYrRnON7"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOgp1omxnQ4x"
      },
      "source": [
        "%cd /content/\n",
        "!mkdir silence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltu6nDHLoYrC"
      },
      "source": [
        "%cd /content/silence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uznZ6eilnak4"
      },
      "source": [
        "from scipy.io import wavfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMermkI8oO5M"
      },
      "source": [
        "silence[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Nivz5ankki"
      },
      "source": [
        "for i in range(silence.shape[0]):\n",
        "  wavfile.write(f'silence{i}.wav',16000,silence[i].astype('int16'))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "210989CMphq7"
      },
      "source": [
        "%cd /content/\n",
        "!zip -r silence silence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SyNjvbsp6kX"
      },
      "source": [
        "!cp silence.zip /content/drive/My\\ Drive/NLP_Dataset/dataset_gan/."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLUYMdhCo9O1"
      },
      "source": [
        "fs, data = wavfile.read('silence0.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38MOzT26pJNW"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ePc7bnlmvOT"
      },
      "source": [
        "del noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qXwevm1nZGT"
      },
      "source": [
        "silence.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvdS8sdTn9Ab"
      },
      "source": [
        "Audio(silence[140],rate=sample_rate,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34fb8LhiBGSD"
      },
      "source": [
        "# **Silence handling (cleaning the dataset)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzhPL02TE4ux"
      },
      "source": [
        "pip install webrtcvad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhNfUdxiE6Qe"
      },
      "source": [
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "import webrtcvad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpGubp3rFpVv"
      },
      "source": [
        "def silenceRemoval(sound_file, fs, mode = 3, chunk = 10):\n",
        "  vad = webrtcvad.Vad()\n",
        "  vad.set_mode(mode)\n",
        "  soundSamples = sound_file.shape[0]\n",
        "  chunkSamples = fs * chunk * (10**-3)\n",
        "  #duration = (soundSamples/fs) * 1000 # put it in ms\n",
        "  # make the duration divisible by the chunk\n",
        "  remain = soundSamples % chunkSamples\n",
        "  # padding my signal with (chunkSamples - remain)\n",
        "  if remain != 0:\n",
        "    zero_padding = int(chunkSamples - remain)\n",
        "    sound_file = np.pad(sound_file, (0,zero_padding), 'constant', constant_values=(0,0))\n",
        "  sound_file = sound_file.reshape(int(soundSamples / chunkSamples),-1)\n",
        "  deleted_rows = []\n",
        "  silence = 0\n",
        "  voice = 0\n",
        "  for i in range(sound_file.shape[0]):\n",
        "    frame = bytes(sound_file[i])\n",
        "    #print(vad.is_speech(frame, fs))\n",
        "    if not vad.is_speech(frame, fs):\n",
        "      #print('silence')\n",
        "      silence+=1\n",
        "      deleted_rows.append(i)\n",
        "    else:\n",
        "      #print('voice activity')\n",
        "      voice +=1\n",
        "  #sound_file = np.delete(sound_file, deleted_rows, axis=0)\n",
        "  #sound_file = sound_file.reshape(sound_file.shape[0]*sound_file.shape[1],)\n",
        "  return silence,voice #sound_file, sound_file.shape[0]\n",
        "  \n",
        "  #return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcW2AmBScRCr"
      },
      "source": [
        "from scipy.io import wavfile\n",
        "sound_file = '/content/drive/My Drive/NLP_Dataset/audio/bed/4c4d2526_nohash_0.wav'\n",
        "fs, data = wavfile.read(sound_file)\n",
        "#data, fs = librosa.core.load(sound_file,sr=None)\n",
        "silence,voice = silenceRemoval(data, fs,mode = 3, chunk = 10)\n",
        "print('number of silence chuncks is  ' + str(silence))\n",
        "print('number of voice chuncksis  ' + str(voice))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yju7qJ8ehTDg"
      },
      "source": [
        "voice_percentage = []\n",
        "data_silence = []\n",
        "silence_id = []\n",
        "threshold = 0.11\n",
        "voice_percentage_vect = []\n",
        "#upper_threshold = 0.97\n",
        "#noised_id = []\n",
        "#data_noised = []\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "for direct in dirs:\n",
        "  print(direct)\n",
        "  if (direct == '_background_noise_'):\n",
        "    continue\n",
        "  waves = [f for f in os.listdir(join(train_audio_path, direct)) if f.endswith('.wav')]\n",
        "  for wav in waves:\n",
        "      sample_rate, samples = wavfile.read(join( join(train_audio_path, direct),wav) )\n",
        "      #samples, sample_rate = librosa.core.load(sound_file,sr=None)\n",
        "\n",
        "      #print(join( join(train_audio_path, direct),wav))\n",
        "      #break\n",
        "      if samples.shape[0] < sample_rate:\n",
        "          zero_padding = sample_rate - samples.shape[0]\n",
        "          # zero padding from the end of the signal\n",
        "          samples = np.pad(samples, (0,zero_padding), 'constant', constant_values=(0,0))\n",
        "\n",
        "      silence,voice = silenceRemoval(samples, sample_rate,mode = 2, chunk = 10)\n",
        "      percentage = voice/(silence+voice)\n",
        "      voice_percentage.append(percentage)\n",
        "      if percentage < threshold:\n",
        "        data_silence.append(str(join( join(train_audio_path, direct),wav)))\n",
        "        silence_id.append(join(direct, wav))\n",
        "        voice_percentage_vect.append(percentage)\n",
        "      #elif percentage >= upper_threshold:\n",
        "        #data_noised.append(str(join( join(train_audio_path, direct),wav)))\n",
        "        #noised_id.append(join(direct, wav))\n",
        "\n",
        "      #break\n",
        "      \n",
        "\n",
        "  #break\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BV_KaVvQC5Y"
      },
      "source": [
        "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLchkK4hpLWp"
      },
      "source": [
        "len(data_silence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaoHUZGakNjA"
      },
      "source": [
        "#len(noised_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr4EuGvByEtp"
      },
      "source": [
        "voice_percentage_vect.index(max(voice_percentage_vect))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y_jDgzy4Pyy"
      },
      "source": [
        "max(voice_percentage_vect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq8Kv9u45Gv_"
      },
      "source": [
        "Z = [x for _,x in sorted(zip(voice_percentage_vect,data_silence))]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKJ-g-NImz0p"
      },
      "source": [
        "sound_file = Z[548]\n",
        "fs, data = wavfile.read(sound_file)\n",
        "zero_padding = sample_rate - data.shape[0]\n",
        "# zero padding from the end of the signal\n",
        "data = np.pad(data, (0,zero_padding), 'constant', constant_values=(0,0))\n",
        "from IPython.display import Audio\n",
        "Audio(data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wc7tQu23VLX"
      },
      "source": [
        "silence,voice = silenceRemoval(data,  sample_rate,mode = 2, chunk = 10)\n",
        "percentage = voice/(silence+voice)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jzdi1v73vIV"
      },
      "source": [
        "percentage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kXsJLohkv46"
      },
      "source": [
        "min(voice_percentage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcHHEkmHmDVv"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(voice_percentage);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e41rv5ZyOQZ"
      },
      "source": [
        "silence_id[1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loDjyAOcyCAB"
      },
      "source": [
        "# **Removing bad samples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXVG_x299oEk"
      },
      "source": [
        "pip install python_speech_features\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGkx0NxpuUtx"
      },
      "source": [
        "from librosa.feature import mfcc\n",
        "from librosa import load\n",
        "import numpy as np\n",
        "\n",
        "#from python_speech_features import mfcc\n",
        "\n",
        "\n",
        "sound_file = '/root/.kaggle/train/train/audio/eight/fd395b74_nohash_2.wav'\n",
        "#fs, data = wavfile.read(sound_file)\n",
        "samples, sample_rate = load(sound_file)#, sr=None)\n",
        "\n",
        "\n",
        "def is_bad_audio(data, fs):\n",
        "    features = mfcc(data, fs)\n",
        "    mean_frequencies = np.mean(features, axis=1)\n",
        "    s = sum(mean_frequencies)\n",
        "    t = np.std(mean_frequencies)\n",
        "    if t < 0.01:\n",
        "        # silent\n",
        "        return True\n",
        "    elif (s > 20 and t < 0.2):\n",
        "        # noisy\n",
        "        return True\n",
        "    elif (s > 30 and t > 1):\n",
        "        # distorted\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "is_bad_audio(samples, sample_rate)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDzvbQGqh9cP"
      },
      "source": [
        "bad_signals = 0\n",
        "total_signal = 0\n",
        "\n",
        "for direct in dirs:\n",
        "  if (direct == '_background_noise_'):\n",
        "    continue\n",
        "  waves = [f for f in os.listdir(join(train_audio_path, direct)) if f.endswith('.wav')]\n",
        "  print('start processing in ' + direct)\n",
        "  for wav in waves:\n",
        "      samples, sample_rate = load(join( join(train_audio_path, direct),wav))\n",
        "      if is_bad_audio(samples, sample_rate) :\n",
        "        bad_signals = bad_signals + 1\n",
        "      #break\n",
        "      total_signal = total_signal + 1\n",
        "  print(str(i))\n",
        "  print('finished processing in ' + direct)\n",
        "  #break\n",
        "\n",
        "\n",
        "print(str(i))\n",
        "      \n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET7tSb1DA90k"
      },
      "source": [
        "from IPython.display import Audio\n",
        "Audio(samples,rate=sample_rate,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9iNvfRwuVEL"
      },
      "source": [
        "# **Padding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jERDE-V5LF8X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6D8O74jLPHs"
      },
      "source": [
        "pip install python_speech_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DND16Qa2LPHx"
      },
      "source": [
        "from python_speech_features import mfcc as mfcc_features\n",
        "from python_speech_features import logfbank"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb8MrSZBrisb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVQ2f4l8LPHy"
      },
      "source": [
        "fbank_feat = logfbank(silence[5],fs,nfilt=40)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCc98TJZrthC"
      },
      "source": [
        "fbank_feat.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyPfp7ynuNHt"
      },
      "source": [
        "def reading_wav(path,sample_rate):\n",
        "  sample_rate, samples = wavfile.read(path)\n",
        "  if samples.shape[0] < sample_rate:\n",
        "    zero_padding = sample_rate - samples.shape[0]\n",
        "    # zero padding from the end of the signal\n",
        "    samples = np.pad(samples, (0,zero_padding), 'constant', constant_values=(0,0))\n",
        "  mfcc = logfbank(samples,sample_rate,nfilt=40)\n",
        "  return samples,mfcc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELBP_ChQvYs7"
      },
      "source": [
        "silence_id = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqRe57r-aBum"
      },
      "source": [
        "# all samples duration should be 1 sec\n",
        "# adding the zero padding\n",
        "import numpy as np\n",
        "#train = []\n",
        "#test = []\n",
        "#validation = []\n",
        "labels_train = []\n",
        "labels_test = []\n",
        "labels_validation = []\n",
        "unknown = []\n",
        "labels_unknown = []\n",
        "\n",
        "\n",
        "train_mfcc = []\n",
        "test_mfcc = []\n",
        "validation_mfcc = []\n",
        "unknown_mfcc = []\n",
        "\n",
        "for direct in dirs:\n",
        "  if (direct == '_background_noise_'):\n",
        "    continue\n",
        "  waves = [f for f in os.listdir(join(train_audio_path, direct)) if f.endswith('.wav')]\n",
        "  print(direct)\n",
        "  for wav in waves:\n",
        "      sound_file = join( join(train_audio_path, direct),wav)\n",
        "      samples,mfcc = reading_wav(sound_file,sample_rate)\n",
        "      if (direct == 'unknown'):\n",
        "        #unknown.append(samples)\n",
        "        unknown_mfcc.append(mfcc)\n",
        "        labels_unknown.append(direct)\n",
        "        continue\n",
        "      # adding the wav to its list\n",
        "      sample_id = join(direct, wav)\n",
        "      if sample_id in silence_id:\n",
        "        continue\n",
        "      if sample_id in testing_id :\n",
        "        # add the sample to test set\n",
        "        #test.append(samples)\n",
        "        test_mfcc.append(mfcc)\n",
        "        labels_test.append(direct)\n",
        "      elif sample_id in validation_id :\n",
        "        # add the sample to the validation set\n",
        "        #validation.append(samples)\n",
        "        validation_mfcc.append(mfcc)\n",
        "        labels_validation.append(direct)\n",
        "      else:\n",
        "        # add the sample to the train set\n",
        "        #train.append(samples)\n",
        "        train_mfcc.append(mfcc)\n",
        "        labels_train.append(direct)\n",
        "        #break\n",
        "      #break\n",
        "      \n",
        "      \n",
        "\n",
        "  #break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fUN6oEhwUbV"
      },
      "source": [
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F4UrXtdrSfm"
      },
      "source": [
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaHgxeuusV4R"
      },
      "source": [
        "silence_mfcc = []\n",
        "labels_silence = []\n",
        "for i in range(silence.shape[0]):\n",
        "  mfcc = logfbank(silence[i],sample_rate,nfilt=40)\n",
        "  silence_mfcc.append(mfcc)\n",
        "  labels_silence.append('silence')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I922oOsJwynL"
      },
      "source": [
        "silence = list(silence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_OoPILyR1mB"
      },
      "source": [
        "def splitting(unknown, percentage):\n",
        "    np.random.seed(1)\n",
        "    np.random.shuffle(unknown)\n",
        "    train_len = int(len(unknown) * percentage)\n",
        "    test_len = int(len(unknown) * (1-percentage) / 2)\n",
        "    train_unknown = unknown[0:train_len]\n",
        "    validation_unknown = unknown[train_len:(train_len+test_len)]\n",
        "    test_unknown = unknown[(train_len+test_len):]\n",
        "    return train_unknown,validation_unknown,test_unknown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWKjNgLux1NW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJrfLdpZXBnQ"
      },
      "source": [
        "train_unknown,validation_unknown,test_unknown = splitting(unknown, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvfFTzdTp1BW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBelccrMy60E"
      },
      "source": [
        "train_unknown_mfcc,validation_unknown_mfcc,test_unknown_mfcc = splitting(unknown_mfcc, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-7MTrMhp5GN"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNYrvoPWw_do"
      },
      "source": [
        "train_silence,validation_silence,test_silence = splitting(silence, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzvYN2miw_dt"
      },
      "source": [
        "train_silence_mfcc,validation_silence_mfcc,test_silence_mfcc = splitting(silence_mfcc, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idF24G4XXLiK"
      },
      "source": [
        "train = train + train_unknown + train_silence\n",
        "validation = validation + validation_unknown + validation_silence\n",
        "test = test + test_unknown + test_silence\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY_CPOkitoDV"
      },
      "source": [
        "labels_train = labels_train + labels_unknown[:len(train_unknown_mfcc)] + labels_silence[:len(train_silence_mfcc)]\n",
        "labels_validation = labels_validation + labels_unknown[:len(validation_unknown_mfcc)] + labels_silence[:len(validation_silence_mfcc)]\n",
        "labels_test = labels_test + labels_unknown[:len(test_unknown_mfcc)] + labels_silence[:len(test_silence_mfcc)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0G6C_z1zIZb"
      },
      "source": [
        "train_mfcc = train_mfcc + train_unknown_mfcc + train_silence_mfcc\n",
        "validation_mfcc = validation_mfcc + validation_unknown_mfcc + validation_silence_mfcc\n",
        "test_mfcc = test_mfcc + test_unknown_mfcc + test_silence_mfcc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSXdLGZvYuDK"
      },
      "source": [
        "#del unknown\n",
        "del labels_unknown\n",
        "#del train_unknown\n",
        "#del validation_unknown\n",
        "#del test_unknown\n",
        "del silence\n",
        "\n",
        "del unknown_mfcc\n",
        "del train_unknown_mfcc\n",
        "del validation_unknown_mfcc\n",
        "del test_unknown_mfcc\n",
        "del silence_mfcc\n",
        "\n",
        "del labels_silence\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh5Z9zXzucK6"
      },
      "source": [
        "del train_silence_mfcc\n",
        "del validation_silence_mfcc\n",
        "del test_silence_mfcc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lVAAoNV-w8Q"
      },
      "source": [
        "# **Submission Reading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kskYVxRh-xe_"
      },
      "source": [
        "yhkhyjk\n",
        "submission = []\n",
        "submission_mfcc = []\n",
        "submission_labels = []\n",
        "\n",
        "\n",
        "submission_path = '/root/.kaggle/test/test/audio/'\n",
        "\n",
        "\n",
        "for i in range(len(submission_set)):\n",
        "  sound_file = submission_set[i].split(',')[0]\n",
        "  submission_labels.append(submission_set[i].split(',')[1])\n",
        "  samples,mfcc = reading_wav(submission_path+sound_file,sample_rate)\n",
        "  submission.append(samples)\n",
        "  submission_mfcc.append(mfcc)\n",
        "  if i%5000 == 0:\n",
        "    print(str(i))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHOg1oHwxV9w"
      },
      "source": [
        "len(submission_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVi8Cd2Iuzuv"
      },
      "source": [
        "def get_submission_mfcc(chunk_len=25000,max_range = 158538,submission_set=submission_set):\n",
        "  submission_path = '/root/.kaggle/test/test/audio/'\n",
        "  submission_mfcc = []\n",
        "  submission_labels = []\n",
        "  random_index = np.random.randint(0,max_range,chunk_len)\n",
        "  random_index = list(random_index)\n",
        "  for i in random_index:\n",
        "    sound_file = submission_set[i].split(',')[0]\n",
        "    submission_labels.append(submission_set[i].split(',')[1])\n",
        "    samples,mfcc = reading_wav(submission_path+sound_file,sample_rate)\n",
        "    submission_mfcc.append(mfcc)\n",
        "\n",
        "  submission_mfcc = np.asarray(submission_mfcc)\n",
        "  submission_mfcc = np.repeat(submission_mfcc[..., np.newaxis], 3, -1)\n",
        "  submission_mfcc = submission_mfcc.reshape(-1,99,40,3)\n",
        "\n",
        "  return submission_mfcc,submission_labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBFOTBf1OW-H"
      },
      "source": [
        "waves = []\n",
        "for i in range(len(submission_set)):\n",
        "  waves.append(submission_set[i].split(',')[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqxs0whERThe"
      },
      "source": [
        "labels_submission = []\n",
        "for i in range(len(submission_set)):\n",
        "  labels_submission.append(submission_set[i].split(',')[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wIXKUdqM7aM"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "start = 0\n",
        "end = 25000\n",
        "submission_path = '/root/.kaggle/test/test/audio/'\n",
        "\n",
        "#submission_time = []\n",
        "\n",
        "for chunk in range(7):\n",
        "    submission_mfcc = []\n",
        "    submission = []\n",
        "    if chunk == 6:\n",
        "        temp = waves[start:]\n",
        "    else:\n",
        "        temp = waves[start:end]\n",
        "    for wav in temp:\n",
        "        samples,mfcc = reading_wav(submission_path+wav,sample_rate)\n",
        "        submission_mfcc.append(mfcc)\n",
        "        submission.append(samples)\n",
        "    start = end\n",
        "    end += 25000        \n",
        "    submission_mfcc = np.asarray(submission_mfcc)\n",
        "    submission = np.asarray(submission)\n",
        "    np.save(f\"/root/.kaggle/test/mfcc_data{chunk}.npy\",submission_mfcc)\n",
        "    np.save(f\"/root/.kaggle/test/data{chunk}.npy\",submission)\n",
        "    del submission_mfcc\n",
        "    del submission\n",
        "    print(str(chunk))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C62aVcQaCYs7"
      },
      "source": [
        "# **List2arr**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ByP_JWZCmuw"
      },
      "source": [
        "# use del to avoid crashing\n",
        "train = np.asarray(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRd2PzsOHjc1"
      },
      "source": [
        "test = np.asarray(test)\n",
        "validation = np.asarray(validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH0OHYCDHl51"
      },
      "source": [
        "train_mfcc = np.asarray(train_mfcc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsVzbaw7Hmj0"
      },
      "source": [
        "test_mfcc = np.asarray(test_mfcc)\n",
        "validation_mfcc = np.asarray(validation_mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzPphSCaHtyq"
      },
      "source": [
        "labels_train = np.asarray(labels_train)\n",
        "labels_test = np.asarray(labels_test)\n",
        "labels_validation = np.asarray(labels_validation)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVbeC_p-y0AB"
      },
      "source": [
        "#submission_labels = np.asarray(submission_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtBED9pHqJMg"
      },
      "source": [
        "#submission_mfcc_chunck = np.asarray(submission_mfcc[:25000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYr9L5HIkNeb"
      },
      "source": [
        "Audio(train[52000],rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdiDJdQCxmvv"
      },
      "source": [
        "train_mfcc.shapelabels_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nF87TX2zhBh"
      },
      "source": [
        "np.unique(labels_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbMZHWDjwNqQ"
      },
      "source": [
        "# **Augmentation(scratch)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1FI0WqswbEQ"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/NLP_Dataset/codes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0cevcl64r2E"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ1dRiVq8EZ2"
      },
      "source": [
        "from augmentation import DataAugForAudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTf0UQAD4tuT"
      },
      "source": [
        "class DataAugForAudio():\n",
        "    \n",
        "    '''\n",
        "    time_shift function parameters:\n",
        "    \n",
        "      audio: choose required audio to shift\n",
        "      sampling_rate; sampling rate of the audio\n",
        "      direction: shift direction: left, right or both(is chosen randomly right or left) \n",
        "                                  and by default: left shift\n",
        "      max_shift: maximum shift of the audio in msec\n",
        "    '''\n",
        "    def time_shift(self,audio,sampling_rate,direction,max_shift):\n",
        "        coverage_maxlimit = (max_shift/1000) * sampling_rate\n",
        "        start = int(np.random.uniform(coverage_maxlimit))\n",
        "        #print(start)\n",
        "        if direction == 'right':\n",
        "            start = -start\n",
        "        elif direction == 'both':\n",
        "            rand_direction = np.random.randint(0, 2)\n",
        "            '''\n",
        "            0: left direction\n",
        "            1: right direction\n",
        "            '''\n",
        "            if rand_direction == 1:\n",
        "                start = -start\n",
        "                \n",
        "        if start >= 0:\n",
        "            audio_shifted = np.r_[audio[start:], np.random.uniform(-0.001,0.001, start)]\n",
        "        else:\n",
        "            audio_shifted = np.r_[np.random.uniform(-0.001,0.001, -start), audio[:start]]\n",
        "        return audio_shifted\n",
        "    \n",
        "    \n",
        "    \n",
        "    '''\n",
        "    noise_injection function parameters:\n",
        "    \n",
        "      audio: choose required audio \n",
        "      noise_factor: intensity of noise randomly chosen   n_f = np.round(random.uniform(0.01,0.09),3) for example\n",
        "      augmentated_zone: (tuple) range of audio duration that will be augmentated\n",
        "      \n",
        "      start = np.round(random.uniform(0,0.4),3)\n",
        "      end = np.round(random.uniform(0.7,1),3)\n",
        "      aug_zone=(start,end)\n",
        "      \n",
        "      background_noise: list of arrays of background noise wav file from kaggle or empty list if white gaussian noise by random.randn\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    def noise_injection(self,audio,noise_factor,augmented_zone,background_noise = []):\n",
        "        start_augmentation = augmented_zone[0]\n",
        "        end_augmentation = augmented_zone[1]\n",
        "        length = len(audio)\n",
        "        if background_noise == []:\n",
        "            noise = np.hstack((np.zeros(int(start_augmentation * length)),  np.random.randn(int((end_augmentation - start_augmentation)*length)) , np.zeros(length - int((end_augmentation * length)))))                \n",
        "        else:\n",
        "            background_noise_sample =  background_noise[np.random.randint(6)]\n",
        "            start_ = np.random.randint(background_noise_sample.shape[0]-length)\n",
        "            noise = background_noise_sample[start_ : start_+length]\n",
        "        if len(noise) != len(audio):\n",
        "            noise = np.pad(noise,(0,len(audio)-len(noise)),'constant',constant_values=(0))\n",
        "        noisy_audio = audio* np.random.uniform(0.8, 1.2) + noise* np.random.uniform(0, 0.2)*noise_factor\n",
        "        return noisy_audio.astype(type(audio[0]))  \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    def speedx(self,sound_array, factor):\n",
        "    ##speed sound by factor\n",
        "        indices = np.round( np.arange(0, len(sound_array), factor) )\n",
        "        indices = indices[indices < len(sound_array)].astype(int)\n",
        "        return sound_array[ indices.astype(int) ]\n",
        "\n",
        "    \n",
        "    def speed_change(self,audio,factor_1,factor_2,zone_1,zone_2):\n",
        "        data_s1 = math.ceil(zone_1 * len(audio)) ##get the size of the first zone\n",
        "        data_s2 = math.ceil(zone_2 * len(audio)) ##get the size of the second zone\n",
        "        if data_s1 < data_s2 :\n",
        "            data_1 = speedx(audio[0:data_s1], factor_1)  ##speed the first zone by factor_1\n",
        "            data_2 = audio[data_s1:data_s2]\n",
        "            data_3 = speedx(audio[data_s2:] , factor_2)  ##speed the third zone by factor_2\n",
        "        if data_s1 >= data_s2 :\n",
        "            data_1 = speedx(audio[0:data_s2] , factor_1)\n",
        "            data_2 = audio[data_s2:data_s1]\n",
        "            data_3 = speedx(audio[data_s1:], factor_2)\n",
        "        audio_f = np.concatenate((data_1,data_2,data_3))  ##concatenate the 3 zones\n",
        "        return audio_f\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def mask(self,audio,mask_with_noise,zone_1,zone_2):\n",
        "        data_s1 = math.ceil(zone_1 * len(audio)) ##get the size of the first zone\n",
        "        data_s2 = math.ceil(zone_2 * len(audio)) ##get the size of the second zone\n",
        "        if mask_with_noise == True :\n",
        "            if data_s1 < data_s2 :\n",
        "                data_1 = audio[0:data_s1] \n",
        "                data_2 = 100*np.random.normal(0,1,data_s2-data_s1)  ##if mask_with_noise == True replace the zone by noise\n",
        "                data_3 = audio[data_s2:] \n",
        "            if data_s1 >= data_s2 :\n",
        "                data_1 = audio[0:data_s2] \n",
        "                data_2 = 100*np.random.normal(0,1,data_s1-data_s2)\n",
        "                data_3 = audio[data_s1:]\n",
        "        if mask_with_noise == False :\n",
        "            if data_s1 < data_s2 :\n",
        "                data_1 = audio[0:data_s1] \n",
        "                data_2 = np.zeros(data_s2-data_s1)\n",
        "                data_3 = audio[data_s2:] \n",
        "            if data_s1 >= data_s2 :\n",
        "                data_1 = audio[0:data_s2] \n",
        "                data_2 = np.zeros(data_s1-data_s2)  ##if mask_with_noise == False replace the noise by zeros\n",
        "                data_3 = audio[data_s1:]\n",
        "        audio_f = np.concatenate((data_1,data_2,data_3))\n",
        "        return audio_f\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def change_volume(self,audio,factor_1,factor_2,zone_1,zone_2):\n",
        "        data_s1 = math.ceil(zone_1 * len(audio))  ##get the size of the first zone\n",
        "        data_s2 = math.ceil(zone_2 * len(audio))  ##get the size of the second zone\n",
        "        if data_s1 < data_s2 :\n",
        "            data_1 = audio[0:data_s1] * factor_1 ##increase the volume (first zone) by factor_1\n",
        "            data_2 = audio[data_s1:data_s2]\n",
        "            data_3 = audio[data_s2:] * factor_2  ##increase the volume (second zone) by factor_2\n",
        "        if data_s1 >= data_s2 :\n",
        "            data_1 = audio[0:data_s2] * factor_1\n",
        "            data_2 = audio[data_s2:data_s1]\n",
        "            data_3 = audio[data_s1:] * factor_2\n",
        "        audio_f = np.concatenate((data_1,data_2,data_3))\n",
        "        return audio_f\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY8Nt3kcwbei"
      },
      "source": [
        "augmentor = DataAugForAudio()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJjSoM7bwbbZ"
      },
      "source": [
        "origin = train[15]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sictRRhUwbXU"
      },
      "source": [
        "origin.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUKmOG6rzIeV"
      },
      "source": [
        "Audio(origin,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ2drn8KzEq7"
      },
      "source": [
        "augmented = augmentor.time_shift(origin,fs,'both',500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJt5RumHCNQU"
      },
      "source": [
        "Audio(augmented,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGjbI2PAwbTA"
      },
      "source": [
        "augmented = augmentor.noise_injection(origin,0.8,[0,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNAr6W63BwDh"
      },
      "source": [
        "Audio(augmented,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKrDgXtTBXn4"
      },
      "source": [
        "# **Augmentation nlpaugdev**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QzfHeU4BWra"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1636MGUB2H-"
      },
      "source": [
        "pip install git+https://github.com/makcedward/nlpaug.git numpy matplotlib python-dotenv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtVZFL97KYFA"
      },
      "source": [
        "import nlpaug.augmenter.audio as naa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW80zJG31tao"
      },
      "source": [
        "sound_file = '/content/drive/My Drive/NLP_Dataset/audio/bed/4c4d2526_nohash_0.wav'\n",
        "#sound_file = '/root/.kaggle/train/train/audio/bed/4c4d2526_nohash_0.wav'\n",
        "data, fs = librosa.core.load(sound_file,sr=None)\n",
        "print('the number of samples are '+ str(data.shape[0]) + '\\n the sampling frequency is '+ str(fs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GHtyUQPhAKO"
      },
      "source": [
        "#dataset = np.tile(data,(3,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFWniQPnhJaW"
      },
      "source": [
        "#dataset.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3WgiwBghzmw"
      },
      "source": [
        "#dataset[2,752]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzyMMUKyKYZi"
      },
      "source": [
        "from IPython.display import Audio\n",
        "Audio(data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb-_nY4bKqKZ"
      },
      "source": [
        "aug_vol = naa.LoudnessAug(zone=(0.1, 0.9),\n",
        "                      coverage=0.45,\n",
        "                      factor=(0.5, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRmkrT5iQj_t"
      },
      "source": [
        "augmented_data = aug_vol.augment(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPMMat_gQo4-"
      },
      "source": [
        "augmented_data[8500]/data[8500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ4dhGU8KYug"
      },
      "source": [
        "Audio(augmented_data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jrq-hhQtUJSV"
      },
      "source": [
        "aug_mask = naa.MaskAug(sampling_rate=fs,\n",
        "                       zone=(0.1, 0.9),\n",
        "                       coverage=0.3,\n",
        "                       #mask_factor=2,\n",
        "                       mask_with_noise=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-vFEDEqUJd6"
      },
      "source": [
        "augmented_data = aug_mask.augment(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91tKf_sSWiqU"
      },
      "source": [
        "augmented_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYulTIokWtdv"
      },
      "source": [
        "Audio(augmented_data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPezNsZiTU8R"
      },
      "source": [
        "type(data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTI1_qA0PWmA"
      },
      "source": [
        "aug_noise_white = naa.NoiseAug(zone=(0, 1),\n",
        "                         coverage=1,\n",
        "                         color='white',\n",
        "                         noises=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myTSK4vvmFHJ"
      },
      "source": [
        "augmented_data = aug_noise_white.augment(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H777zKDbmpt9"
      },
      "source": [
        "Audio(augmented_data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYvXKgHz3NWl"
      },
      "source": [
        "aug_noise_pink = naa.NoiseAug(zone=(0.1, 0.9),\n",
        "                         coverage=1,\n",
        "                         color='pink',\n",
        "                         noises=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BjscOFz3NWr"
      },
      "source": [
        "augmented_data = aug_noise_pink.augment(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d3TPWqk3NWs"
      },
      "source": [
        "Audio(augmented_data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yEO37gs3M4V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK8OjzdY4i7b"
      },
      "source": [
        "aug_noise_blue = naa.NoiseAug(zone=(0.1, 0.8),\n",
        "                         coverage=0.002,\n",
        "                         color='blue',\n",
        "                         noises=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJJxbKiy4i7k"
      },
      "source": [
        "augmented_data = aug_noise_blue.augment(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb6zkcmk4i7q"
      },
      "source": [
        "Audio(augmented_data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bczkaTss5WtY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIVjCvRQ5XMO"
      },
      "source": [
        "aug_noise_purple = naa.NoiseAug(zone=(0.1, 0.8),\n",
        "                         coverage=0.0002,\n",
        "                         color='purple',\n",
        "                         noises=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twTtjSBi5XMU"
      },
      "source": [
        "augmented_data = aug_noise_purple.augment(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDc1-Nko5XMW"
      },
      "source": [
        "Audio(augmented_data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCBUOXt14j7n"
      },
      "source": [
        "type(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChEciO3w7VIk"
      },
      "source": [
        "aug_pitch=naa.PitchAug(fs,\n",
        "                       zone=(0.1, 0.9),\n",
        "                       coverage=0.5,\n",
        "                       factor=(-10, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecEXNIhy-PJs"
      },
      "source": [
        "augmented_data = aug_pitch.augment(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6X45h8F-Pck"
      },
      "source": [
        "Audio(augmented_data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JK7TkybA7K3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuXyfXiiBFHM"
      },
      "source": [
        "aug_shift=naa.ShiftAug(fs,\n",
        "                       duration=0.35,\n",
        "                       direction='random')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK1js7DKCKLk"
      },
      "source": [
        "augmented_data = aug_shift.augment(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWXSCte5Cijq"
      },
      "source": [
        "Audio(augmented_data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Oyft2PRDCvY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnpH1D2KDC7W"
      },
      "source": [
        "aug_speed = naa.SpeedAug(zone=(0.1, 0.9),\n",
        "                         coverage=0.5,\n",
        "                         factor=(0.5, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W80C4MwADC3G"
      },
      "source": [
        "augmented_data = aug_speed.augment(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thfPO5VLErAj"
      },
      "source": [
        "augmented_data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAgd6MVrESH1"
      },
      "source": [
        "if fs > augmented_data.shape[0]:\n",
        "  zero_padding = fs - augmented_data.shape[0]\n",
        "  # zero padding from the end of the signal\n",
        "  augmented_data = np.pad(augmented_data, (0,zero_padding), 'constant', constant_values=(0,0))\n",
        "else:\n",
        "  augmented_data = augmented_data[0:fs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXuV-SoIEEjB"
      },
      "source": [
        "Audio(augmented_data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BsTrO3rGXwx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB4CMR1bGX-f"
      },
      "source": [
        "aug_vt = naa.VtlpAug(fs,\n",
        "                     zone=(0.1, 0.9),\n",
        "                     coverage=0.7,\n",
        "                     fhi=4800,\n",
        "                     factor=(0.7, 7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlXJ-WrLJmUK"
      },
      "source": [
        "augmented_data = aug_vt.augment(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJeBUif-JmUO"
      },
      "source": [
        "augmented_data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IYNW7F8JmUR"
      },
      "source": [
        "if fs > augmented_data.shape[0]:\n",
        "  zero_padding = fs - augmented_data.shape[0]\n",
        "  # zero padding from the end of the signal\n",
        "  augmented_data = np.pad(augmented_data, (0,zero_padding), 'constant', constant_values=(0,0))\n",
        "else:\n",
        "  augmented_data = augmented_data[0:fs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUkJ4-bvJmUS"
      },
      "source": [
        "Audio(augmented_data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ3ku5adJr-t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-__nxkXPGte"
      },
      "source": [
        "aug_crop = naa.CropAug(fs,\n",
        "                       zone=(0.1, 0.9),\n",
        "                       coverage=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJOhyGeORmn7"
      },
      "source": [
        "augmented_data = aug_crop.augment(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx59mBsVRrQE"
      },
      "source": [
        "augmented_data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuQEo0EmRzVl"
      },
      "source": [
        "if fs > augmented_data.shape[0]:\n",
        "  zero_padding = fs - augmented_data.shape[0]\n",
        "  # zero padding from the end of the signal\n",
        "  augmented_data = np.pad(augmented_data, (0,zero_padding), 'constant', constant_values=(0,0))\n",
        "else:\n",
        "  augmented_data = augmented_data[0:fs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECt44pUWRzVp"
      },
      "source": [
        "Audio(augmented_data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9cgBZNwSsHy"
      },
      "source": [
        "augmented_data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJkuSfPYwUGJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6nh1lniWCIR"
      },
      "source": [
        "# **Augmentation (nlpaug)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no_Kc18QWPrL"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i17MQCcIWPrS"
      },
      "source": [
        "pip install git+https://github.com/makcedward/nlpaug.git numpy matplotlib python-dotenv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBVrhY2TteU_"
      },
      "source": [
        "import nlpaug.augmenter.audio as naa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMC41_CHWQu2"
      },
      "source": [
        "def input_padding(signal,fs):\n",
        "  if fs > signal.shape[0]:\n",
        "    zero_padding = fs - signal.shape[0]\n",
        "    # zero padding from the end of the signal\n",
        "    signal = np.pad(signal, (0,zero_padding), 'constant', constant_values=(0,0))\n",
        "  else:\n",
        "    signal = signal[0:fs]\n",
        "  return signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxhhHCQ7W9aJ"
      },
      "source": [
        "aug_vol = naa.LoudnessAug(zone=(0.1, 0.9),\n",
        "                      coverage=0.25,\n",
        "                      factor=(0.5, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5-Yga9bW9aO"
      },
      "source": [
        "aug_mask = naa.MaskAug(sampling_rate=fs,\n",
        "                       zone=(0.1, 0.9),\n",
        "                       coverage=0.125,\n",
        "                       #mask_factor=2,\n",
        "                       mask_with_noise=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSW3RgPqW9aS"
      },
      "source": [
        "aug_noise_white = naa.NoiseAug(zone=(0.1, 0.9),\n",
        "                         coverage=0.4,\n",
        "                         color='white',\n",
        "                         noises=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3IkgJOjW9aU"
      },
      "source": [
        "aug_noise_pink = naa.NoiseAug(zone=(0.1, 0.9),\n",
        "                         coverage=1,\n",
        "                         color='pink',\n",
        "                         noises=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3rQoMT6W9aV"
      },
      "source": [
        "aug_noise_blue = naa.NoiseAug(zone=(0.1, 0.8),\n",
        "                         coverage=0.002,\n",
        "                         color='blue',\n",
        "                         noises=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK1iUO39W9aZ"
      },
      "source": [
        "aug_noise_purple = naa.NoiseAug(zone=(0.1, 0.8),\n",
        "                         coverage=0.0002,\n",
        "                         color='purple',\n",
        "                         noises=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3D5XNPxW9ab"
      },
      "source": [
        "aug_pitch=naa.PitchAug(fs,\n",
        "                       zone=(0.1, 0.9),\n",
        "                       coverage=0.4,\n",
        "                       factor=(-10, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuaJAOEOW9ac"
      },
      "source": [
        "aug_shift=naa.ShiftAug(fs,\n",
        "                       duration=0.125,\n",
        "                       direction='random')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce2PmEQOW9ae"
      },
      "source": [
        "aug_speed = naa.SpeedAug(zone=(0.1, 0.9),\n",
        "                         coverage=0.25,\n",
        "                         factor=(0.5, 1.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evXSkEq2W9ai"
      },
      "source": [
        "aug_vt = naa.VtlpAug(fs,\n",
        "                     zone=(0.1, 0.9),\n",
        "                     coverage=0.4,\n",
        "                     fhi=4800,\n",
        "                     factor=(0.7, 7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta4m3kn5W9ak"
      },
      "source": [
        "aug_crop = naa.CropAug(fs,\n",
        "                       zone=(0.1, 0.9),\n",
        "                       coverage=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQerbrHm0oOI"
      },
      "source": [
        "augmented_data = aug_crop.augment(train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EanubG-16Jw"
      },
      "source": [
        "augmented_data = np.asarray(augmented_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JetOcOKe1_Lc"
      },
      "source": [
        "augmented_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73Ibr1OJ2JnF"
      },
      "source": [
        "augmented_data = input_padding(augmented_data,fs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5IrMvjk2Q9W"
      },
      "source": [
        "augmented_data[None,:].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APFqCtGz2q3b"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYpgtEsV2tE1"
      },
      "source": [
        "see = np.append(train,augmented_data[None,:],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2R_AE-i2wIs"
      },
      "source": [
        "see.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzWoD54iKWDB"
      },
      "source": [
        "code = np.random.randint(0,2, size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk6C7X1RN9io"
      },
      "source": [
        "code[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMEtJTlTSY6a"
      },
      "source": [
        "train_temp = train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bxWDSeeSeGY"
      },
      "source": [
        "train = train_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuFbzb1oSa_r"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEJd-OkR0Qhc"
      },
      "source": [
        "examples = train.shape[0]\n",
        "number_of_augmentation = 32\n",
        "number_of_filters = 11\n",
        "for example in range(examples):\n",
        "  # new example\n",
        "  for i in range(number_of_augmentation):\n",
        "    # new augment to the same example\n",
        "    code = np.random.randint(0,2, size=number_of_filters)\n",
        "    temp = train[example]\n",
        "    if code[0] == 1:\n",
        "      temp = aug_vol.augment(temp)\n",
        "    if code[1] == 1:\n",
        "      temp = aug_mask.augment(temp)\n",
        "    if code[2] == 1:\n",
        "      temp = aug_noise_white.augment(temp)\n",
        "    if code[3] == 1:\n",
        "      temp = aug_noise_pink.augment(temp)\n",
        "    if code[4] == 1:\n",
        "      temp = aug_noise_blue.augment(temp)\n",
        "    if code[5] == 1:\n",
        "      temp = aug_noise_purple.augment(temp)\n",
        "    if code[6] == 1:\n",
        "      temp = aug_pitch.augment(temp)\n",
        "    if code[7] == 1:\n",
        "      temp = aug_shift.augment(temp)\n",
        "    if code[8] == 1:\n",
        "      temp = aug_speed.augment(temp)\n",
        "    if code[9] == 1:\n",
        "      temp = aug_vt.augment(temp)\n",
        "    if code[10] == 1:\n",
        "      temp = aug_crop.augment(temp)\n",
        "\n",
        "    temp = np.asarray(temp)\n",
        "    temp = input_padding(temp,fs)\n",
        "    train = np.append(train,temp[None,:],axis=0)\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNRy8QLMQtFp"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKTMp97zuG1I"
      },
      "source": [
        "Audio(train[79],rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbTiUmENPJw7"
      },
      "source": [
        "# **Augmentation(dev)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHvYC34ueQNk"
      },
      "source": [
        "def noise_injection(data, noise_interval):\n",
        "    # data is passed (samples,time-axis)\n",
        "    noise = np.random.randn(data.shape[0],data.shape[1])\n",
        "    noise_factor = np.random.uniform(noise_interval[0],noise_interval[1],noise.shape[0])\n",
        "    noise_factor = noise_factor[:,None]\n",
        "    print(str(noise_factor))\n",
        "    augmented_data = data + noise_factor * noise\n",
        "    # Cast back to same data type\n",
        "    augmented_data = augmented_data.astype(type(data[0]))\n",
        "    return augmented_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju3J7Ehi_egy"
      },
      "source": [
        "def time_shifting(data, sampling_rate, shift_interval_time):\n",
        "    # shifting interval time is in ms\n",
        "    # data is passed (samples,time-axis)\n",
        "    shift = np.random.randint(low = sampling_rate * shift_interval_time[0],\n",
        "                              high = sampling_rate * shift_interval_time[1],\n",
        "                              size = (data.shape[0]))\n",
        "    augmented_data = np.roll(data, shift)\n",
        "    # Set to silence for heading/ tailing\n",
        "    if shift > 0:\n",
        "        augmented_data[:shift] = 0\n",
        "    else:\n",
        "        augmented_data[shift:] = 0\n",
        "    return augmented_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z7dnDBnpOM7"
      },
      "source": [
        "data = data[None,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIWr3N9_ysPe"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_lQBg5FzHEM"
      },
      "source": [
        "data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHuqf-gcy4f9"
      },
      "source": [
        "len(data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8CUoeqAeKrv"
      },
      "source": [
        "from IPython.display import Audio\n",
        "Audio(data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2BezTMA18HT"
      },
      "source": [
        "type(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZVmiu9S14Me"
      },
      "source": [
        "noise_interval = [0.01, 0.001]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws9RsC57ceJR"
      },
      "source": [
        "augmented_data = noise_injection(data, noise_interval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-s6H1HEzcg2"
      },
      "source": [
        "augmented_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aiev5hlTcpli"
      },
      "source": [
        "Audio(augmented_data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG-E2DLB6TZ6"
      },
      "source": [
        "noise.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQHXmJ2r1c5_"
      },
      "source": [
        "noised = 0.0001* noise[300] + data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN-bZRZdef6t"
      },
      "source": [
        "noised = noised.astype(type(data[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KxY_YIp98lS"
      },
      "source": [
        "noised.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVJUN2i530nE"
      },
      "source": [
        "Audio(noised,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7EwrVLl8c7b"
      },
      "source": [
        "silence,voice = silenceRemoval(noised.T, fs,mode = 2, chunk = 10)\n",
        "percentage = voice/(silence+voice)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dlEB0Pje5y4"
      },
      "source": [
        "percentage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vcugv2UlBcnp"
      },
      "source": [
        "# **Feature Scaling and Encoding the labels**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8isExFDJ2jPe"
      },
      "source": [
        "#temp = labels_train\n",
        "#temp2 = labels_submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-pxnYZ5hPPy"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "labels_train = labelencoder.fit_transform(labels_train)\n",
        "labels_test = labelencoder.transform(labels_test)\n",
        "labels_validation = labelencoder.transform(labels_validation)\n",
        "#labels_submission1 = labelencoder.transform(labels_submission)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7M92UR4zr34"
      },
      "source": [
        "labelencoder.inverse_transform(labels_train[50:51])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU_iNXJjaF1O"
      },
      "source": [
        "labels_submission = labels_submission1\n",
        "del labels_submission1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF0CA__z1vlS"
      },
      "source": [
        "import pickle\n",
        "labelencoder_filename = \"labelencoderN.sav\"\n",
        "path = '/content/drive/My Drive/NLP_Dataset/scratch/'\n",
        "pickle.dump(labelencoder, open(path+labelencoder_filename, 'wb'))\n",
        "#loaded_model = pickle.load(open(filename, 'rb'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3MTHApMjV6K"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "train = scaler.fit_transform(train)\n",
        "test = scaler.transform(test)\n",
        "validation = scaler.transform(validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpHDTHj92dGA"
      },
      "source": [
        "import pickle\n",
        "scaler_filename = \"scalerN.save\"\n",
        "path = '/content/drive/My Drive/NLP_Dataset/scratch/'\n",
        "pickle.dump(scaler, open(path+scaler_filename, 'wb'))\n",
        "#loaded_model = pickle.load(open(filename, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5ZTDgulSJz3"
      },
      "source": [
        "#def get_submission_TD(chunk, scaler=scaler):\n",
        "  #data = np.load(f\"/root/.kaggle/test/data{chunk}.npy\")\n",
        "  #data = scaler.transform|(data)\n",
        "  #data = data.reshape(data.shape[0], data.shape[1],1)# X.reshape(samples, timesteps, features)\n",
        "  #return data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGTxGEBrUKn8"
      },
      "source": [
        "#def get_submission_mfcc(chunk):\n",
        "  #data = np.load(f\"/root/.kaggle/test/mfcc_data{chunk}.npy\")\n",
        "  #data = np.repeat(data[..., np.newaxis], 3, -1)\n",
        "  #data = data.reshape(-1,99,40,3)\n",
        "  #return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LphrxvWO7iUo"
      },
      "source": [
        "print('Number of samples of train is '+ str(train.shape[0]))\n",
        "print('Number of samples of validation is '+ str(validation.shape[0]))\n",
        "print('Number of samples of test is '+ str(test.shape[0]))\n",
        "print('Number of features is '+ str(train.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM7qXRNP57lA"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=train.shape[1]/2, random_state=42)\n",
        "train = pca.fit_transform(train)\n",
        "test = pca.transform(test)\n",
        "validation = pca.transform(validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e0tAAlJhGkt"
      },
      "source": [
        "# **Transfer Learning(Resnet)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2U2qElwA8Kp"
      },
      "source": [
        "train_mfcc.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3egNSHBYBQDh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhcM6MJChMg9"
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense,GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.models import load_model\n",
        "\n",
        "import matplotlib.pyplot  as plt\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XQZvUVSqp1h"
      },
      "source": [
        "train_mfcc = np.repeat(train_mfcc[..., np.newaxis], 3, -1)\n",
        "validation_mfcc = np.repeat(validation_mfcc[..., np.newaxis], 3, -1)\n",
        "test_mfcc = np.repeat(test_mfcc[..., np.newaxis], 3, -1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fa7r7NqNhKM"
      },
      "source": [
        "train_mfcc.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLOrnXu7A09-"
      },
      "source": [
        "train_mfcc = train_mfcc.reshape(-1,99,40,3)\n",
        "validation_mfcc = validation_mfcc.reshape(-1,99,40,3)\n",
        "test_mfcc = test_mfcc.reshape(-1,99,40,3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMo0dFVXPjC0"
      },
      "source": [
        "y_train = to_categorical(labels_train)\n",
        "y_val = to_categorical(labels_validation)\n",
        "y_test = to_categorical(labels_test)\n",
        "#y_submission = to_categorical(labels_submission)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBOUFujBKJi4"
      },
      "source": [
        "train_mfcc.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pfcYVoMdUI4"
      },
      "source": [
        "train_mfcc.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GZdu0WiCch7"
      },
      "source": [
        "resnet50_input = Input(shape = (99, 40, 3), name = 'Image_input')\n",
        "model_resnet50_conv = ResNet50(weights= 'imagenet', include_top=False, input_shape= (99, 40, 3))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHQDabG-NwBL"
      },
      "source": [
        "model_resnet50_conv.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIzPp94AMdJI"
      },
      "source": [
        "output_resnet50_conv = model_resnet50_conv(resnet50_input)\n",
        "#Add the fully-connected layers \n",
        "\n",
        "x=GlobalAveragePooling2D()(output_resnet50_conv)\n",
        "#x = Flatten()(output_resnet50_conv)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x = Dropout(0.3)(x) # **reduce dropout \n",
        "x=Dense(512,activation='relu')(x) #dense layer 2\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "#x=Dense(256,activation='relu')(x) #dense layer 3\n",
        "#x = Dropout(0.3)(x)\n",
        "\n",
        "x = Dense(32, activation='softmax', name='predictions')(x)\n",
        "\n",
        "\n",
        "resnet50_pretrained = Model(input = resnet50_input, output = x)\n",
        "# for layer in resnet50_pretrained.layers[:2]:\n",
        "#     layer.trainable=False\n",
        "# for layer in resnet50_pretrained.layers[2:]:\n",
        "#     layer.trainable=True\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh029-TIRo3u"
      },
      "source": [
        "resnet50_pretrained.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46xTB5KKR2s9"
      },
      "source": [
        "# Compile CNN model\n",
        "#adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0)\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "resnet50_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGizKWCrR_YO"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz5_TYlkSpp3"
      },
      "source": [
        "best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/transfer_learning/resnet_semi_supervised.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=7)\n",
        "batch_size = 16\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0g7k3rYTrWz"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/NLP_Dataset/transfer_learning/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JDa4-lMTxBx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZdxPkkt6Lmj"
      },
      "source": [
        "import time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXXcvxNp7If0"
      },
      "source": [
        "train_mfcc.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJLmvdN87rW9"
      },
      "source": [
        "temp_mfcc,temp_labels = get_submission_mfcc()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAf95rwZ8mZR"
      },
      "source": [
        "temp_labels = np.asarray(temp_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGlV2W508qWM"
      },
      "source": [
        "np.unique(temp_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVDaRli1b30D"
      },
      "source": [
        "for _ in range(50):\n",
        "\n",
        "  #start_time = time.time()\n",
        "  \n",
        "  temp_mfcc,temp_labels = get_submission_mfcc()\n",
        "  temp_labels = np.asarray(temp_labels)\n",
        "  temp_labels = labelencoder.transform(temp_labels)\n",
        "  temp_labels = to_categorical(temp_labels)\n",
        "\n",
        "  \n",
        "  train_all = np.concatenate((train_mfcc,temp_mfcc))\n",
        "  y_all = np.concatenate((y_train,temp_labels))\n",
        "\n",
        "  del temp_labels\n",
        "  del temp_mfcc\n",
        "\n",
        "  #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "  #break\n",
        "  history = resnet50_pretrained.fit(x=train_all,\n",
        "                y=y_all,\n",
        "                batch_size=batch_size,\n",
        "                epochs=1,\n",
        "                verbose=1,\n",
        "                shuffle=True,\n",
        "                validation_data=(validation_mfcc, y_val),\n",
        "                callbacks=[best_model_saved,es])\n",
        "  \n",
        "  del train_all\n",
        "  del y_all \n",
        "\n",
        "\n",
        " \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtruQUEF3-Bq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7JfF7tqJxx2"
      },
      "source": [
        "#del train_all\n",
        "#del y_all     \n",
        "#del temp_labels   \n",
        "#del temp_mfcc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewY-49bB7P-l"
      },
      "source": [
        "temp_labels.shape\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek-ogRgN7aEm"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG4slSFieNDA"
      },
      "source": [
        "chunk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqGBLPFIS1eh"
      },
      "source": [
        "history = resnet50_pretrained.fit(x=train_mfcc,\n",
        "              y=y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=100,\n",
        "              verbose=1,\n",
        "              shuffle=True,\n",
        "              validation_data=(validation_mfcc, y_val),\n",
        "              callbacks=[best_model_saved,es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PHUEumV1Ytl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qCHNyZF1hQZ"
      },
      "source": [
        "plotting = resnet50_pretrained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY0gsSCk1hQd"
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize = (10, 5))\n",
        "axes[0].plot(range(1, len(plotting.history.history['acc']) + 1), plotting.history.history['acc'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Accuracy')\n",
        "axes[0].plot(range(1, len(plotting.history.history['val_acc']) + 1), plotting.history.history['val_acc'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Accuracy')\n",
        "axes[0].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[0].set_ylabel('Accuracy',fontsize = 14)\n",
        "axes[0].set_title('Training and Validation Accuracies', fontsize = 14)\n",
        "axes[0].legend(loc = 'best')\n",
        "axes[1].plot(range(1, len(plotting.history.history['loss']) + 1), plotting.history.history['loss'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Loss')\n",
        "axes[1].plot(range(1, len(plotting.history.history['val_loss']) + 1), plotting.history.history['val_loss'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Loss')\n",
        "axes[1].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[1].set_ylabel('Loss',fontsize = 14)\n",
        "axes[1].set_title('Training and Validation Losses', fontsize = 14)\n",
        "axes[1].legend(loc = 'best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbvEbp_Cpd_e"
      },
      "source": [
        "resnet50_pretrained = load_model('/content/drive/My Drive/NLP_Dataset/transfer_learning/resnet_semi_supervised.hdf5')\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "\n",
        "resnet50_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n",
        "   \n",
        "resnet50_pretrained.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1kj_KYDo1qh"
      },
      "source": [
        "results = resnet50_pretrained.evaluate(train_mfcc, y_train, batch_size=128)\n",
        "print('train loss, train acc:', results)\n",
        "results = resnet50_pretrained.evaluate(validation_mfcc, y_val, batch_size=128)\n",
        "print('validation loss, validation acc:', results)\n",
        "results = resnet50_pretrained.evaluate(test_mfcc, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYm48RYlpunZ"
      },
      "source": [
        "best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/transfer_learning/resnetsemi.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=7)\n",
        "batch_size = 16\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iApFm-bV5uEp"
      },
      "source": [
        "for _ in range(50):\n",
        "\n",
        "  #start_time = time.time()\n",
        "  \n",
        "  temp_mfcc,temp_labels = get_submission_mfcc()\n",
        "  temp_labels = np.asarray(temp_labels)\n",
        "  temp_labels = labelencoder.transform(temp_labels)\n",
        "  temp_labels = to_categorical(temp_labels)\n",
        "\n",
        "  \n",
        "  train_all = np.concatenate((train_mfcc,temp_mfcc))\n",
        "  y_all = np.concatenate((y_train,temp_labels))\n",
        "\n",
        "  del temp_labels\n",
        "  del temp_mfcc\n",
        "\n",
        "  #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "  #break\n",
        "  history = resnet50_pretrained.fit(x=train_all,\n",
        "                y=y_all,\n",
        "                batch_size=batch_size,\n",
        "                epochs=1,\n",
        "                verbose=1,\n",
        "                shuffle=True,\n",
        "                validation_data=(validation_mfcc, y_val),\n",
        "                callbacks=[best_model_saved,es]) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YImpavP9kina"
      },
      "source": [
        "# **Transfer Learning (VGG-16)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFIzLv-yvlcd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2ac29vqlQNR"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k32Cg9mNktf5"
      },
      "source": [
        "vgg16_input = Input(shape = (99, 40, 3), name = 'Image_input')\n",
        "model_vgg16_conv = VGG16(weights='imagenet', include_top=False, input_tensor = vgg16_input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhSlIcuJlVXG"
      },
      "source": [
        "model_vgg16_conv.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yETJ2z-Kvpsy"
      },
      "source": [
        "output_vgg16_conv = model_vgg16_conv(vgg16_input)\n",
        "\n",
        "#Add the fully-connected layers \n",
        "x=GlobalAveragePooling2D()(output_vgg16_conv)\n",
        "x=Dense(512,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x = Dropout(0.2)(x) # **reduce dropout \n",
        "x=Dense(512,activation='relu')(x) #dense layer 2\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "#x = Dense(512,activation='relu')(x) #dense layer 3\n",
        "x = Dense(32, activation='softmax', name='predictions')(x)\n",
        "\n",
        "vgg16_pretrained = Model(input = vgg16_input, output = x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbLf2FcEmJtJ"
      },
      "source": [
        "vgg16_pretrained.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSVQbC5UmMCT"
      },
      "source": [
        "# Compile CNN model\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "vgg16_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb3tJ-k2mPgy"
      },
      "source": [
        "best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/transfer_learning/vgg16semi.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=7)\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRVjgE54zoiH"
      },
      "source": [
        "for _ in range(4):\n",
        "\n",
        "  #start_time = time.time()\n",
        "  \n",
        "  temp_mfcc,temp_labels = get_submission_mfcc()\n",
        "  temp_labels = np.asarray(temp_labels)\n",
        "  temp_labels = labelencoder.transform(temp_labels)\n",
        "  temp_labels = to_categorical(temp_labels)\n",
        "\n",
        "  \n",
        "  train_all = np.concatenate((train_mfcc,temp_mfcc))\n",
        "  y_all = np.concatenate((y_train,temp_labels))\n",
        "\n",
        "  del temp_labels\n",
        "  del temp_mfcc\n",
        "\n",
        "  #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "  #break\n",
        "  history = vgg16_pretrained.fit(x=train_all,\n",
        "                y=y_all,\n",
        "                batch_size=batch_size,\n",
        "                epochs=1,\n",
        "                verbose=1,\n",
        "                shuffle=True,\n",
        "                validation_data=(validation_mfcc, y_val),\n",
        "                callbacks=[best_model_saved,es])\n",
        "  \n",
        "  del train_all\n",
        "  del y_all \n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wel1GOQIP1ow"
      },
      "source": [
        "vgg16_pretrained = load_model('/content/drive/My Drive/NLP_Dataset/transfer_learning/vgg16semi.hdf5')\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "  \n",
        "vgg16_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n",
        "     \n",
        "vgg16_pretrained.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kCfMK9SP88x"
      },
      "source": [
        "results = vgg16_pretrained.evaluate(train_mfcc, y_train, batch_size=128)\n",
        "print('train loss, train acc:', results)\n",
        "results = vgg16_pretrained.evaluate(validation_mfcc, y_val, batch_size=128)\n",
        "print('validation loss, validation acc:', results)\n",
        "results = vgg16_pretrained.evaluate(test_mfcc, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bXsMPM3mfiI"
      },
      "source": [
        "history = vgg16_pretrained.fit(x=train_mfcc,\n",
        "              y=y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=75,\n",
        "              verbose=1,\n",
        "              shuffle=True,\n",
        "              validation_data=(validation_mfcc, y_val),\n",
        "              callbacks=[best_model_saved,es])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-Ghr0-Jz5q9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrBGrjm8zszh"
      },
      "source": [
        "plotting = vgg16_pretrained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i1W_GxNnCRT"
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize = (10, 5))\n",
        "axes[0].plot(range(1, len(plotting.history.history['acc']) + 1), plotting.history.history['acc'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Accuracy')\n",
        "axes[0].plot(range(1, len(plotting.history.history['val_acc']) + 1), plotting.history.history['val_acc'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Accuracy')\n",
        "axes[0].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[0].set_ylabel('Accuracy',fontsize = 14)\n",
        "axes[0].set_title('Training and Validation Accuracies', fontsize = 14)\n",
        "axes[0].legend(loc = 'best')\n",
        "axes[1].plot(range(1, len(plotting.history.history['loss']) + 1), plotting.history.history['loss'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Loss')\n",
        "axes[1].plot(range(1, len(plotting.history.history['val_loss']) + 1), plotting.history.history['val_loss'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Loss')\n",
        "axes[1].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[1].set_ylabel('Loss',fontsize = 14)\n",
        "axes[1].set_title('Training and Validation Losses', fontsize = 14)\n",
        "axes[1].legend(loc = 'best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5F3YFu3zQ5V"
      },
      "source": [
        "results = vgg16_pretrained.evaluate(train_mfcc, y_train, batch_size=128)\n",
        "print('train loss, train acc:', results)\n",
        "results = vgg16_pretrained.evaluate(validation_mfcc, y_val, batch_size=128)\n",
        "print('validation loss, validation acc:', results)\n",
        "results = vgg16_pretrained.evaluate(test_mfcc, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sWjCwmz0fnX"
      },
      "source": [
        "sdff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7inUnIA0gxL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eToUFWHw0hAP"
      },
      "source": [
        "# **Transfer Learning (VGG-19)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg_U1cun0hAR"
      },
      "source": [
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aULTktAF0hAU"
      },
      "source": [
        "vgg19_input = Input(shape = (99, 40, 3), name = 'Image_input')\n",
        "model_vgg19_conv = VGG19(weights='imagenet', include_top=False, input_tensor = vgg19_input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99zWAU4Y0hAX"
      },
      "source": [
        "model_vgg19_conv.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnnADgyE0hAZ"
      },
      "source": [
        "output_vgg19_conv = model_vgg19_conv(vgg19_input)\n",
        "#Add the fully-connected layers \n",
        "\n",
        "x=GlobalAveragePooling2D()(output_vgg19_conv)\n",
        "x=Dense(256,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x = Dropout(0.3)(x) # **reduce dropout \n",
        "x=Dense(128,activation='relu')(x) #dense layer 2\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(32, activation='softmax', name='predictions')(x)\n",
        "\n",
        "\n",
        "vgg19_pretrained = Model(input = vgg19_input, output = x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2scOraV0hAb"
      },
      "source": [
        "vgg19_pretrained.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1XYiQA30hAd"
      },
      "source": [
        "# Compile CNN model\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "vgg19_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEo1OH0n0hAe"
      },
      "source": [
        "best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/transfer_learning/vgg19semi.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=7)\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqeNl3pRmkEn"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/NLP_Dataset/transfer_learning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pev_DVlRmuMT"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAn3U8ymRHLn"
      },
      "source": [
        "for _ in range(50):\n",
        "\n",
        "  #start_time = time.time()\n",
        "  \n",
        "  temp_mfcc,temp_labels = get_submission_mfcc()\n",
        "  temp_labels = np.asarray(temp_labels)\n",
        "  temp_labels = labelencoder.transform(temp_labels)\n",
        "  temp_labels = to_categorical(temp_labels)\n",
        "\n",
        "  \n",
        "  train_all = np.concatenate((train_mfcc,temp_mfcc))\n",
        "  y_all = np.concatenate((y_train,temp_labels))\n",
        "\n",
        "  del temp_labels\n",
        "  del temp_mfcc\n",
        "\n",
        "  #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "  #break\n",
        "  history = vgg19_pretrained.fit(x=train_all,\n",
        "                y=y_all,\n",
        "                batch_size=batch_size,\n",
        "                epochs=1,\n",
        "                verbose=1,\n",
        "                shuffle=True,\n",
        "                validation_data=(validation_mfcc, y_val),\n",
        "                callbacks=[best_model_saved,es])\n",
        "  \n",
        "  del train_all\n",
        "  del y_all \n",
        "\n",
        "       \n",
        "     \n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NgnCrjqxqsU"
      },
      "source": [
        "vgg19_pretrained = load_model('/content/drive/My Drive/NLP_Dataset/transfer_learning/vgg19semi.hdf5')\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "     \n",
        "vgg19_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n",
        "                 \n",
        "vgg19_pretrained.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fOcGTcAxqsZ"
      },
      "source": [
        "results = vgg19_pretrained.evaluate(train_mfcc, y_train, batch_size=128)\n",
        "print('train loss, train acc:', results)\n",
        "results = vgg19_pretrained.evaluate(validation_mfcc, y_val, batch_size=128)\n",
        "print('validation loss, validation acc:', results)\n",
        "results = vgg19_pretrained.evaluate(test_mfcc, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP48pcMS0hAf"
      },
      "source": [
        "history = vgg19_pretrained.fit(x=train_mfcc,\n",
        "              y=y_train,   \n",
        "              batch_size=batch_size,\n",
        "              epochs=75,\n",
        "              verbose=1,\n",
        "              shuffle=True,\n",
        "              validation_data=(validation_mfcc, y_val),\n",
        "              callbacks=[best_model_saved,es])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fJFvwoU0hAh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv7OT4Lz0hAk"
      },
      "source": [
        "plotting = vgg19_pretrained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkrY_-HP0hAm"
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize = (10, 5))\n",
        "axes[0].plot(range(1, len(plotting.history.history['acc']) + 1), plotting.history.history['acc'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Accuracy')\n",
        "axes[0].plot(range(1, len(plotting.history.history['val_acc']) + 1), plotting.history.history['val_acc'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Accuracy')\n",
        "axes[0].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[0].set_ylabel('Accuracy',fontsize = 14)\n",
        "axes[0].set_title('Training and Validation Accuracies', fontsize = 14)\n",
        "axes[0].legend(loc = 'best')\n",
        "axes[1].plot(range(1, len(plotting.history.history['loss']) + 1), plotting.history.history['loss'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Loss')\n",
        "axes[1].plot(range(1, len(plotting.history.history['val_loss']) + 1), plotting.history.history['val_loss'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Loss')\n",
        "axes[1].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[1].set_ylabel('Loss',fontsize = 14)\n",
        "axes[1].set_title('Training and Validation Losses', fontsize = 14)\n",
        "axes[1].legend(loc = 'best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0mMxO-G0hAn"
      },
      "source": [
        "results = vgg19_pretrained.evaluate(train_mfcc, y_train, batch_size=128)\n",
        "print('train loss, train acc:', results)\n",
        "results = vgg19_pretrained.evaluate(validation_mfcc, y_val, batch_size=128)\n",
        "print('validation loss, validation acc:', results)\n",
        "results = vgg19_pretrained.evaluate(test_mfcc, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky2YGmiP7fWV"
      },
      "source": [
        "sdd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LhueYgS7gy6"
      },
      "source": [
        "# **Transfer Learning (MobileNet)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuFVWMSQ7gy7"
      },
      "source": [
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMBqIHID7gy-"
      },
      "source": [
        "mobilenet_input = Input(shape = (99, 40, 3), name = 'Image_input')\n",
        "model_mobilenet_conv = MobileNet(weights='imagenet', include_top=False, input_tensor = mobilenet_input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngiMfv3O7gy_"
      },
      "source": [
        "model_mobilenet_conv.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypxABg567gzC"
      },
      "source": [
        "output_mobilenet_conv = model_mobilenet_conv(mobilenet_input)\n",
        "\n",
        "#Add the fully-connected layers \n",
        "x=GlobalAveragePooling2D()(output_mobilenet_conv)\n",
        "x=Dense(512,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x = Dropout(0.2)(x) # **reduce dropout \n",
        "x=Dense(512,activation='relu')(x) #dense layer 2\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "#x = Dense(512,activation='relu')(x) #dense layer 3\n",
        "x = Dense(32, activation='softmax', name='predictions')(x)\n",
        "\n",
        "mobilenet_pretrained = Model(input = mobilenet_input, output = x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8HaNvWn7gzD"
      },
      "source": [
        "mobilenet_pretrained.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGsJd83g7gzF"
      },
      "source": [
        "# Compile CNN model\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "mobilenet_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Goq-JV7gzH"
      },
      "source": [
        "best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/transfer_learning/mobilenetsemiN.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=7)\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HyxJ6Dzy-4C"
      },
      "source": [
        "for _ in range(50):\n",
        "\n",
        "  #start_time = time.time()\n",
        "  \n",
        "  temp_mfcc,temp_labels = get_submission_mfcc()\n",
        "  temp_labels = np.asarray(temp_labels)\n",
        "  temp_labels = labelencoder.transform(temp_labels)\n",
        "  temp_labels = to_categorical(temp_labels)\n",
        "\n",
        "  \n",
        "  train_all = np.concatenate((train_mfcc,temp_mfcc))\n",
        "  y_all = np.concatenate((y_train,temp_labels))\n",
        "\n",
        "  del temp_labels\n",
        "  del temp_mfcc\n",
        "\n",
        "  #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "  #break\n",
        "  history = mobilenet_pretrained.fit(x=train_all,\n",
        "                y=y_all,\n",
        "                batch_size=batch_size,\n",
        "                epochs=1,\n",
        "                verbose=1,\n",
        "                shuffle=True,\n",
        "                validation_data=(validation_mfcc, y_val),\n",
        "                callbacks=[best_model_saved,es])\n",
        "  \n",
        "  del train_all\n",
        "  del y_all \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsmhYHJ4y-4I"
      },
      "source": [
        "mobilenet_pretrained = load_model('/content/drive/My Drive/NLP_Dataset/transfer_learning/mobilenetsemiN.hdf5')\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "\n",
        "mobilenet_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n",
        "   \n",
        "mobilenet_pretrained.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNveEH_Ay-4L"
      },
      "source": [
        "results = mobilenet_pretrained.evaluate(train_mfcc, y_train, batch_size=128)\n",
        "print('train loss, train acc:', results)\n",
        "results = mobilenet_pretrained.evaluate(validation_mfcc, y_val, batch_size=128)\n",
        "print('validation loss, validation acc:', results)\n",
        "results = mobilenet_pretrained.evaluate(test_mfcc, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StZJVu4j7gzI"
      },
      "source": [
        "history = mobilenet_pretrained.fit(x=train_mfcc,\n",
        "              y=y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=75,\n",
        "              verbose=1,\n",
        "              shuffle=True,\n",
        "              validation_data=(validation_mfcc, y_val),\n",
        "              callbacks=[best_model_saved,es])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49sJBgx97gzK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQQoTEDX7gzN"
      },
      "source": [
        "plotting = mobilenet_pretrained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un98bG647gzQ"
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize = (10, 5))\n",
        "axes[0].plot(range(1, len(plotting.history.history['acc']) + 1), plotting.history.history['acc'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Accuracy')\n",
        "axes[0].plot(range(1, len(plotting.history.history['val_acc']) + 1), plotting.history.history['val_acc'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Accuracy')\n",
        "axes[0].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[0].set_ylabel('Accuracy',fontsize = 14)\n",
        "axes[0].set_title('Training and Validation Accuracies', fontsize = 14)\n",
        "axes[0].legend(loc = 'best')\n",
        "axes[1].plot(range(1, len(plotting.history.history['loss']) + 1), plotting.history.history['loss'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Loss')\n",
        "axes[1].plot(range(1, len(plotting.history.history['val_loss']) + 1), plotting.history.history['val_loss'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Loss')\n",
        "axes[1].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[1].set_ylabel('Loss',fontsize = 14)\n",
        "axes[1].set_title('Training and Validation Losses', fontsize = 14)\n",
        "axes[1].legend(loc = 'best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0O26nG97gzS"
      },
      "source": [
        "results = mobilenet_pretrained.evaluate(train_mfcc, y_train, batch_size=128)\n",
        "print('train loss, train acc:', results)\n",
        "results = mobilenet_pretrained.evaluate(validation_mfcc, y_val, batch_size=128)\n",
        "print('validation loss, validation acc:', results)\n",
        "results = mobilenet_pretrained.evaluate(test_mfcc, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjUk9-u0_8yj"
      },
      "source": [
        "gj"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApqGpQh9__yO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw3zmQ8vAAFc"
      },
      "source": [
        "# **Transfer Learning (DenseNet)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDYPfcO-AAFf"
      },
      "source": [
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GlHeT_wAAFk"
      },
      "source": [
        "densenet_input = Input(shape = (99, 40, 3), name = 'Image_input')\n",
        "model_densenet_conv = DenseNet169(weights='imagenet', include_top=False, input_tensor = densenet_input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eOlrimAAAFn"
      },
      "source": [
        "model_densenet_conv.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv32QbKmAAFr"
      },
      "source": [
        "output_densenet_conv = model_densenet_conv(densenet_input)\n",
        "\n",
        "#Add the fully-connected layers \n",
        "x=GlobalAveragePooling2D()(output_densenet_conv)\n",
        "x=Dense(512,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x = Dropout(0.2)(x) # **reduce dropout \n",
        "x=Dense(512,activation='relu')(x) #dense layer 2\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "#x = Dense(512,activation='relu')(x) #dense layer 3\n",
        "x = Dense(32, activation='softmax', name='predictions')(x)\n",
        "\n",
        "densenet_pretrained = Model(input = densenet_input, output = x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jJMVoSbAAFu"
      },
      "source": [
        "densenet_pretrained.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzhPxDbkAAFw"
      },
      "source": [
        "# Compile CNN model\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "densenet_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcnwELTQAAFz"
      },
      "source": [
        "best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/transfer_learning/densenetsemi.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=7)\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdgaDJMvipYu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts8uod3Gipjo"
      },
      "source": [
        "for _ in range(5):\n",
        "\n",
        "  #start_time = time.time()\n",
        "  \n",
        "  temp_mfcc,temp_labels = get_submission_mfcc()\n",
        "  temp_labels = np.asarray(temp_labels)\n",
        "  temp_labels = labelencoder.transform(temp_labels)\n",
        "  temp_labels = to_categorical(temp_labels)\n",
        "\n",
        "  \n",
        "  train_all = np.concatenate((train_mfcc,temp_mfcc))\n",
        "  y_all = np.concatenate((y_train,temp_labels))\n",
        "\n",
        "  del temp_labels\n",
        "  del temp_mfcc\n",
        "\n",
        "  #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "  #break\n",
        "  history = densenet_pretrained.fit(x=train_all,\n",
        "                y=y_all,\n",
        "                batch_size=batch_size,\n",
        "                epochs=1,\n",
        "                verbose=1,\n",
        "                shuffle=True,\n",
        "                validation_data=(validation_mfcc, y_val),\n",
        "                callbacks=[best_model_saved,es])\n",
        "  \n",
        "  del train_all\n",
        "  del y_all \n",
        "        \n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA_SEESSfqzz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY7PleaVipjs"
      },
      "source": [
        "densenet_pretrained = load_model('/content/drive/My Drive/NLP_Dataset/transfer_learning/densenetsemi.hdf5')\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "  \n",
        "densenet_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n",
        "     \n",
        "densenet_pretrained.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNnhijzFipju"
      },
      "source": [
        "results = densenet_pretrained.evaluate(train_mfcc, y_train, batch_size=128)\n",
        "print('train loss, train acc:', results)\n",
        "results = densenet_pretrained.evaluate(validation_mfcc, y_val, batch_size=128)\n",
        "print('validation loss, validation acc:', results)\n",
        "results = densenet_pretrained.evaluate(test_mfcc, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbiJtbecAAF0"
      },
      "source": [
        "history = densenet_pretrained.fit(x=train_mfcc,\n",
        "              y=y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=75,\n",
        "              verbose=1,\n",
        "              shuffle=True,\n",
        "              validation_data=(validation_mfcc, y_val),\n",
        "              callbacks=[best_model_saved,es])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QObJJZ5AAF4"
      },
      "source": [
        "plotting = densenet_pretrained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxWIKpjSAAF5"
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize = (10, 5))\n",
        "axes[0].plot(range(1, len(plotting.history.history['acc']) + 1), plotting.history.history['acc'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Accuracy')\n",
        "axes[0].plot(range(1, len(plotting.history.history['val_acc']) + 1), plotting.history.history['val_acc'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Accuracy')\n",
        "axes[0].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[0].set_ylabel('Accuracy',fontsize = 14)\n",
        "axes[0].set_title('Training and Validation Accuracies', fontsize = 14)\n",
        "axes[0].legend(loc = 'best')\n",
        "axes[1].plot(range(1, len(plotting.history.history['loss']) + 1), plotting.history.history['loss'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Loss')\n",
        "axes[1].plot(range(1, len(plotting.history.history['val_loss']) + 1), plotting.history.history['val_loss'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Loss')\n",
        "axes[1].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[1].set_ylabel('Loss',fontsize = 14)\n",
        "axes[1].set_title('Training and Validation Losses', fontsize = 14)\n",
        "axes[1].legend(loc = 'best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYcAO0vLAAF7"
      },
      "source": [
        "results = densenet_pretrained.evaluate(train_mfcc, y_train, batch_size=128)\n",
        "print('train loss, train acc:', results)\n",
        "results = densenet_pretrained.evaluate(validation_mfcc, y_val, batch_size=128)\n",
        "print('validation loss, validation acc:', results)\n",
        "results = densenet_pretrained.evaluate(test_mfcc, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBGpT1vpAAF9"
      },
      "source": [
        "sdd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmsmI7OkAAF9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcEEcNEwlpZ8"
      },
      "source": [
        "# **Transfer Learning (NASNet) (uncompleted)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NgA2XjmlnRl"
      },
      "source": [
        "from keras.applications.nasnet import NASNetLarge\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxV7UUVKlnRs"
      },
      "source": [
        "nasnet_input = Input(shape = (99, 40, 3), name = 'Image_input')\n",
        "model_nasnet_conv = NASNetLarge(weights='imagenet', include_top=False, input_tensor = nasnet_input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF8LmEbQlnRu"
      },
      "source": [
        "model_nasnet_conv.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfAFwohHlnRz"
      },
      "source": [
        "output_nasnet_conv = model_nasnet_conv(nasnet_input)\n",
        "\n",
        "#Add the fully-connected layers \n",
        "x=GlobalAveragePooling2D()(output_nasnet_conv)\n",
        "x=Dense(512,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x = Dropout(0.2)(x) # **reduce dropout \n",
        "x=Dense(512,activation='relu')(x) #dense layer 2\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "#x = Dense(512,activation='relu')(x) #dense layer 3\n",
        "x = Dense(32, activation='softmax', name='predictions')(x)\n",
        "\n",
        "nasnet_pretrained = Model(input = nasnet_input, output = x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK-I0z90lnR1"
      },
      "source": [
        "nasnet_pretrained.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGo_kDSxlnR3"
      },
      "source": [
        "# Compile CNN model\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "nasnet_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uk49A0KlnR6"
      },
      "source": [
        "best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/transfer_learning/nasnetsemi.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=7)\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLFJIG5rhalz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7nVJJUzhavo"
      },
      "source": [
        "for _ in range(5):\n",
        "\n",
        "  #start_time = time.time()\n",
        "  \n",
        "  temp_mfcc,temp_labels = get_submission_mfcc()\n",
        "  temp_labels = np.asarray(temp_labels)\n",
        "  temp_labels = labelencoder.transform(temp_labels)\n",
        "  temp_labels = to_categorical(temp_labels)\n",
        "\n",
        "  \n",
        "  train_all = np.concatenate((train_mfcc,temp_mfcc))\n",
        "  y_all = np.concatenate((y_train,temp_labels))\n",
        "\n",
        "  del temp_labels\n",
        "  del temp_mfcc\n",
        "\n",
        "  #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "  #break\n",
        "  history = nasnet_pretrained.fit(x=train_all,\n",
        "                y=y_all,\n",
        "                batch_size=batch_size,\n",
        "                epochs=1,\n",
        "                verbose=1,\n",
        "                shuffle=True,\n",
        "                validation_data=(validation_mfcc, y_val),\n",
        "                callbacks=[best_model_saved,es])\n",
        "  \n",
        "  del train_all\n",
        "  del y_all  \n",
        "\n",
        "   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhmH5uMFhavt"
      },
      "source": [
        "nasnet_pretrained = load_model('/content/drive/My Drive/NLP_Dataset/transfer_learning/nasnetsemi.hdf5')\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "  \n",
        "nasnet_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n",
        "     \n",
        "nasnet_pretrained.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wLJ1HMAhavw"
      },
      "source": [
        "results = nasnet_pretrained.evaluate(train_mfcc, y_train, batch_size=128)\n",
        "print('train loss, train acc:', results)  \n",
        "results = nasnet_pretrained.evaluate(validation_mfcc, y_val, batch_size=128)\n",
        "print('validation loss, validation acc:', results)\n",
        "results = nasnet_pretrained.evaluate(test_mfcc, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CQNle9WlnR8"
      },
      "source": [
        "history = nasnet_pretrained.fit(x=train_mfcc,\n",
        "              y=y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=75,\n",
        "              verbose=1,\n",
        "              shuffle=True,\n",
        "              validation_data=(validation_mfcc, y_val),\n",
        "              callbacks=[best_model_saved,es])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIrTqFlzlnR_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sVwXV4xlnSF"
      },
      "source": [
        "plotting = nasnet_pretrained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L-MF_L2lnSH"
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize = (10, 5))\n",
        "axes[0].plot(range(1, len(plotting.history.history['acc']) + 1), plotting.history.history['acc'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Accuracy')\n",
        "axes[0].plot(range(1, len(plotting.history.history['val_acc']) + 1), plotting.history.history['val_acc'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Accuracy')\n",
        "axes[0].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[0].set_ylabel('Accuracy',fontsize = 14)\n",
        "axes[0].set_title('Training and Validation Accuracies', fontsize = 14)\n",
        "axes[0].legend(loc = 'best')\n",
        "axes[1].plot(range(1, len(plotting.history.history['loss']) + 1), plotting.history.history['loss'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Loss')\n",
        "axes[1].plot(range(1, len(plotting.history.history['val_loss']) + 1), plotting.history.history['val_loss'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Loss')\n",
        "axes[1].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[1].set_ylabel('Loss',fontsize = 14)\n",
        "axes[1].set_title('Training and Validation Losses', fontsize = 14)\n",
        "axes[1].legend(loc = 'best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kdus3p2lnSK"
      },
      "source": [
        "results = nasnet_pretrained.evaluate(train_mfcc, y_train, batch_size=128)\n",
        "print('train loss, train acc:', results)\n",
        "results = nasnet_pretrained.evaluate(validation_mfcc, y_val, batch_size=128)\n",
        "print('validation loss, validation acc:', results)\n",
        "results = nasnet_pretrained.evaluate(test_mfcc, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfAI0IME4ca2"
      },
      "source": [
        "nasnet_pretrained = load_model('/content/drive/My Drive/NLP_Dataset/transfer_learning/nasnetN.hdf5')\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "\n",
        "nasnet_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n",
        "   \n",
        "nasnet_pretrained.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTAIQLtKnCi7"
      },
      "source": [
        "# **Transfer Learning (Inception) problem**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S-FLVEunCi-"
      },
      "source": [
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSh13nlWnCjA"
      },
      "source": [
        "inception_input = Input(shape = (99, 40, 3), name = 'Image_input')\n",
        "#model_InceptionV3_conv = InceptionV3(weights='imagenet', include_top=False, input_tensor = inception_input)\n",
        "model_InceptionV3_conv = InceptionResNetV2(weights='imagenet', include_top=False, input_tensor = inception_input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji7OGD8SnCjB"
      },
      "source": [
        "model_InceptionV3_conv.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUB96kHVnCjD"
      },
      "source": [
        "output_InceptionV3_conv = model_InceptionV3_conv(inception_input)\n",
        "\n",
        "#Add the fully-connected layers \n",
        "x=GlobalAveragePooling2D()(output_InceptionV3_conv)\n",
        "x=Dense(512,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x = Dropout(0.2)(x) # **reduce dropout \n",
        "x=Dense(512,activation='relu')(x) #dense layer 2\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "#x = Dense(512,activation='relu')(x) #dense layer 3\n",
        "x = Dense(31, activation='softmax', name='predictions')(x)\n",
        "\n",
        "inception_pretrained = Model(input = inception_input, output = x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWN9Z2MZnCjF"
      },
      "source": [
        "inception_pretrained.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PQ2C3lXnCjH"
      },
      "source": [
        "# Compile CNN model\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "inception_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCPM05o0nCjJ"
      },
      "source": [
        "best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/transfer_learning/inception.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=7)\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAtuK15FnCjL"
      },
      "source": [
        "history = inception_pretrained.fit(x=train_mfcc,\n",
        "              y=y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=100,\n",
        "              verbose=1,\n",
        "              shuffle=True,\n",
        "              validation_data=(validation_mfcc, y_val),\n",
        "              callbacks=[best_model_saved,es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR1y9W9frrgn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAoipM9FrrsA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT2vGqsm1tYs"
      },
      "source": [
        "plotting = inception_pretrained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xnx6G0k61tYu"
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize = (10, 5))\n",
        "axes[0].plot(range(1, len(plotting.history.history['acc']) + 1), plotting.history.history['acc'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Accuracy')\n",
        "axes[0].plot(range(1, len(plotting.history.history['val_acc']) + 1), plotting.history.history['val_acc'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Accuracy')\n",
        "axes[0].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[0].set_ylabel('Accuracy',fontsize = 14)\n",
        "axes[0].set_title('Training and Validation Accuracies', fontsize = 14)\n",
        "axes[0].legend(loc = 'best')\n",
        "axes[1].plot(range(1, len(plotting.history.history['loss']) + 1), plotting.history.history['loss'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Loss')\n",
        "axes[1].plot(range(1, len(plotting.history.history['val_loss']) + 1), plotting.history.history['val_loss'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Loss')\n",
        "axes[1].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[1].set_ylabel('Loss',fontsize = 14)\n",
        "axes[1].set_title('Training and Validation Losses', fontsize = 14)\n",
        "axes[1].legend(loc = 'best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk45gwH7rxzy"
      },
      "source": [
        "# **Transfer Learning (Xception) low acc**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyiQ5iy9rxz0"
      },
      "source": [
        "from keras.applications.xception import Xception"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N56hXMkVrxz2"
      },
      "source": [
        "xception_input = Input(shape = (99, 40, 3), name = 'Image_input')\n",
        "model_xception_conv = Xception(weights='imagenet', include_top=False, input_tensor = xception_input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpAy3Alirxz4"
      },
      "source": [
        "model_xception_conv.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG-auKF7rxz5"
      },
      "source": [
        "output_xception_conv = model_xception_conv(xception_input)\n",
        "\n",
        "#Add the fully-connected layers \n",
        "x=GlobalAveragePooling2D()(output_xception_conv)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x = Dropout(0.4)(x) # **reduce dropout \n",
        "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "#x = Dense(512,activation='relu')(x) #dense layer 3\n",
        "x = Dense(32, activation='softmax', name='predictions')(x)\n",
        "\n",
        "xception_pretrained = Model(input = xception_input, output = x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzT_A5h7rxz6"
      },
      "source": [
        "xception_pretrained.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcHiS51brxz8"
      },
      "source": [
        "# Compile CNN model\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "xception_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLSeBq03rxz-"
      },
      "source": [
        "best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/transfer_learning/xceptionN.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=7)\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btKbs9IBrxz_"
      },
      "source": [
        "history = xception_pretrained.fit(x=train_mfcc,\n",
        "              y=y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=100,\n",
        "              verbose=1,\n",
        "              shuffle=True,\n",
        "              validation_data=(validation_mfcc, y_val),\n",
        "              callbacks=[best_model_saved,es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8FIrFvo34Ca"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anBEV3pD3_Ie"
      },
      "source": [
        "plotting = xception_pretrained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9B41ddz3_Ij"
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize = (10, 5))\n",
        "axes[0].plot(range(1, len(plotting.history.history['acc']) + 1), plotting.history.history['acc'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Accuracy')\n",
        "axes[0].plot(range(1, len(plotting.history.history['val_acc']) + 1), plotting.history.history['val_acc'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Accuracy')\n",
        "axes[0].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[0].set_ylabel('Accuracy',fontsize = 14)\n",
        "axes[0].set_title('Training and Validation Accuracies', fontsize = 14)\n",
        "axes[0].legend(loc = 'best')\n",
        "axes[1].plot(range(1, len(plotting.history.history['loss']) + 1), plotting.history.history['loss'], linestyle = 'solid', marker = '.', color = 'crimson', label = 'Training Loss')\n",
        "axes[1].plot(range(1, len(plotting.history.history['val_loss']) + 1), plotting.history.history['val_loss'], linestyle = 'solid', marker = '.', color = 'dodgerblue', label = 'Validation Loss')\n",
        "axes[1].set_xlabel('Epochs', fontsize = 14)\n",
        "axes[1].set_ylabel('Loss',fontsize = 14)\n",
        "axes[1].set_title('Training and Validation Losses', fontsize = 14)\n",
        "axes[1].legend(loc = 'best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ejuFIrLzAlD"
      },
      "source": [
        "results = xception_pretrained.evaluate(train_mfcc, y_train, batch_size=128)\n",
        "print('train loss, train acc:', results)\n",
        "results = xception_pretrained.evaluate(validation_mfcc, y_val, batch_size=128)\n",
        "print('validation loss, validation acc:', results)\n",
        "results = xception_pretrained.evaluate(test_mfcc, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSBcS64D4E3y"
      },
      "source": [
        "# **Ensembling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR0mHHkX4CVg"
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78bCd1aC4he0"
      },
      "source": [
        "vgg_model = load_model('/content/drive/My Drive/NLP_Dataset/transfer_learning/vgg16.hdf5')\n",
        "resnet_model = load_model('/content/drive/My Drive/NLP_Dataset/transfer_learning/resnet.hdf5')\n",
        "xception_model = load_model('/content/drive/My Drive/NLP_Dataset/transfer_learning/xception.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzXI_0DjzqJj"
      },
      "source": [
        "# **Scratch Model raw data trying**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGTU0dGXzpSN"
      },
      "source": [
        "#from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import keras.backend as K\n",
        "from keras import regularizers\n",
        "from keras.layers import Lambda\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.layers.core import Activation, Dense\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot  as plt\n",
        "\n",
        "num_classes = len(np.unique(labels_train))\n",
        "audio_len = train.shape[1]\n",
        "num_waves = train.shape[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g7cw-oBZnnO"
      },
      "source": [
        "num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST36C2Aq2iff"
      },
      "source": [
        "def rawdataModel(num_classes=num_classes,num_waves=num_waves,audio_len=audio_len):\n",
        "    print('Using raw data Model')\n",
        "    m = Sequential()\n",
        "    m.add(Conv1D(128,\n",
        "                 input_shape=[audio_len, 1],\n",
        "                 kernel_size=80,\n",
        "                 strides=4,\n",
        "                 padding='same',\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 kernel_regularizer=regularizers.l2(l=0.0001)))\n",
        "    m.add(BatchNormalization())\n",
        "    m.add(Activation('relu'))\n",
        "    m.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "    m.add(Conv1D(128,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 padding='same',\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 kernel_regularizer=regularizers.l2(l=0.0001)))\n",
        "    m.add(BatchNormalization())\n",
        "    m.add(Activation('relu'))\n",
        "    m.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "    m.add(Conv1D(256,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 padding='same',\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 kernel_regularizer=regularizers.l2(l=0.0001)))\n",
        "    m.add(BatchNormalization())\n",
        "    m.add(Activation('relu'))\n",
        "    m.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "    m.add(Conv1D(512,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 padding='same',\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 kernel_regularizer=regularizers.l2(l=0.0001)))\n",
        "    m.add(BatchNormalization())\n",
        "    m.add(Activation('relu'))\n",
        "    m.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "    m.add(Lambda(lambda x: K.mean(x, axis=1))) # Same as GAP for 1D Conv Layer\n",
        "    m.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return m\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0FV-2D1hRZo"
      },
      "source": [
        "def m_rec(num_classes=num_classes,num_waves=num_waves,audio_len=audio_len):\n",
        "    from keras.layers.recurrent import LSTM\n",
        "    print('Using Model LSTM 1')\n",
        "    m = Sequential()\n",
        "    m.add(Conv1D(64,\n",
        "                 input_shape=[audio_len, 1],\n",
        "                 kernel_size=80,\n",
        "                 strides=4,\n",
        "                 padding='same',\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 kernel_regularizer=regularizers.l2(l=0.0001)))\n",
        "    m.add(Activation('relu'))\n",
        "    m.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "\n",
        "    m.add(Conv1D(64,\n",
        "                 input_shape=[audio_len, 1],\n",
        "                 kernel_size=80,\n",
        "                 strides=4,\n",
        "                 padding='same',\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 kernel_regularizer=regularizers.l2(l=0.0001)))\n",
        "    m.add(BatchNormalization())\n",
        "    m.add(Activation('relu'))\n",
        "    m.add(AveragePooling1D(pool_size=4, strides=None))\n",
        "\n",
        "\n",
        "    m.add(LSTM(32,\n",
        "               kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "               return_sequences=True,\n",
        "               dropout=0.2))\n",
        "    m.add(LSTM(32,\n",
        "               kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "               return_sequences=False,\n",
        "               dropout=0.2))\n",
        "    m.add(Dense(32))\n",
        "    m.add(Dense(num_classes, activation='softmax'))\n",
        "    return m\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY7Vnr1q4FfY"
      },
      "source": [
        "model = rawdataModel(num_classes=num_classes,num_waves=num_waves,audio_len=audio_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owyeoqBLhUAd"
      },
      "source": [
        "model2 = m_rec(num_classes=num_classes,num_waves=num_waves,audio_len=audio_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te9in_NELUsD"
      },
      "source": [
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n",
        "   \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phr9ogrxhp6A"
      },
      "source": [
        "sgd = optimizers.SGD(lr = 0.005)\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n",
        "   \n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmAQcrJMVeGR"
      },
      "source": [
        "train = train.reshape(train.shape[0], train.shape[1],1)# X.reshape(samples, timesteps, features)\n",
        "validation = validation.reshape(validation.shape[0], validation.shape[1],1)# X.reshape(samples, timesteps, features)\n",
        "test = test.reshape(test.shape[0], test.shape[1],1)# X.reshape(samples, timesteps, features)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjW8CB77WjO4"
      },
      "source": [
        "#train = train.T\n",
        "#validation = validation.T\n",
        "train.shape\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(labels_train)\n",
        "y_val = to_categorical(labels_validation)\n",
        "y_test = to_categorical(labels_test)\n",
        "y_submission = to_categorical(labels_submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R79zHeyXXfoV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmG72Kn3Xf4u"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OukqDgqMLWoZ"
      },
      "source": [
        "#reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=10, min_lr=0.0001, verbose=1)\n",
        "#best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/models/best_loss_model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/scratch/raw_dataN.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=15)\n",
        "\n",
        "batch_size = 16\n",
        "history = model.fit(x=train,\n",
        "              y=y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=50,\n",
        "              verbose=1,\n",
        "              shuffle=True,\n",
        "              validation_data=(validation, y_val),\n",
        "              callbacks=[best_model_saved])#,es])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJkWEraCJoOv"
      },
      "source": [
        "best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/scratch/raw_dataN2.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=15)\n",
        "\n",
        "batch_size = 64\n",
        "history = model2.fit(x=train,\n",
        "              y=y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=50,\n",
        "              verbose=1,\n",
        "              shuffle=True,\n",
        "              validation_data=(validation, y_val),\n",
        "              callbacks=[best_model_saved])#,es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRTvOpzwxC34"
      },
      "source": [
        "Load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO9IUUeRxB7E"
      },
      "source": [
        "model = load_model('/content/drive/My Drive/NLP_Dataset/scratch/raw_dataN2.hdf5')\n",
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n",
        "   \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkavlurF46kS"
      },
      "source": [
        "results = model.evaluate(train, y_train, batch_size=128)\n",
        "print('train loss, train acc:', results)\n",
        "results = model.evaluate(validation, y_val, batch_size=128)\n",
        "print('validation loss, validation acc:', results)\n",
        "results = model.evaluate(test, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYfmlzd5xYGi"
      },
      "source": [
        "best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/scratch/raw_dataN2.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=15)\n",
        "\n",
        "batch_size = 16\n",
        "history = model.fit(x=train,\n",
        "              y=y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=150,\n",
        "              verbose=1,\n",
        "              shuffle=True,\n",
        "              validation_data=(validation, y_val),\n",
        "              callbacks=[best_model_saved])#,es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5sxHDGjjmUP"
      },
      "source": [
        "# **Scratch Model MFCC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBiFnUJjjukj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWeU76rNjuok"
      },
      "source": [
        "train_mfcc = train_mfcc.reshape(-1,99,34,1)\n",
        "validation_mfcc = validation_mfcc.reshape(-1,99,34,1)\n",
        "test_mfcc = test_mfcc.reshape(-1,99,34,1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYW9m2xcmbuX"
      },
      "source": [
        "test_mfcc.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_eORhZbkloe"
      },
      "source": [
        "num_classes = 31"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFn8-u9_j4kp"
      },
      "source": [
        "def m5_mfcc(num_classes=num_classes):\n",
        "    print('Using Model M5')\n",
        "    m = Sequential()\n",
        "    m.add(Conv2D(128,\n",
        "                 input_shape=(99, 34, 1),\n",
        "                 kernel_size=80,\n",
        "                 strides=4,\n",
        "                 padding='same',\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 kernel_regularizer=regularizers.l2(l=0.0007)))\n",
        "    m.add(BatchNormalization())\n",
        "    m.add(Activation('relu'))\n",
        "    m.add(MaxPooling2D(pool_size=4, strides=None))\n",
        "    \n",
        "    \n",
        "\n",
        "    ################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "    #################################################################################################\n",
        "    m.add(Flatten())\n",
        "    #m.add(Lambda(lambda x: K.mean(x, axis=1)))  # Same as GAP for 1D Conv Layer\n",
        "    #######################################################################################\n",
        "    m.add(Dense(512,activation='relu',activity_regularizer=regularizers.l2(0.0004)))\n",
        "    #m.add(BatchNormalization())\n",
        "    #m.add(Dense(128,activation='relu'))\n",
        "    m.add(BatchNormalization())\n",
        "    #######################################################################################\n",
        "\n",
        "    m.add(Dense(num_classes, activation='softmax'))\n",
        "    return m\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5owCb3T9j4kt"
      },
      "source": [
        "model = m5_mfcc(num_classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX_sS1B9j4kw"
      },
      "source": [
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n",
        "   \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H7fuyBHj4kz"
      },
      "source": [
        "#train = train.T\n",
        "#validation = validation.T\n",
        "#train.shape\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(labels_train)\n",
        "y_val = to_categorical(labels_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igcYFqXHj4k1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXtgPTaEj4k2"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWILVhA0j4k4"
      },
      "source": [
        "#reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=10, min_lr=0.0001, verbose=1)\n",
        "#best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/models/best_loss_model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/scratch/MFCC.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=15)\n",
        "\n",
        "batch_size = 16\n",
        "history = model.fit(x=train_mfcc,\n",
        "              y=y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=150,\n",
        "              verbose=1,\n",
        "              shuffle=True,\n",
        "              validation_data=(validation_mfcc, y_val),\n",
        "              callbacks=[best_model_saved])#,es])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWK6Jxp8j4k5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MekLyMvCOGDg"
      },
      "source": [
        "# **Loading the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AOM--SEOUJC"
      },
      "source": [
        "model = load_model('/content/drive/My Drive/NLP_Dataset/models/best_acc_model.hdf5')\n",
        "model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwhhrJ9Ny-hM"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJQJ5sWOzHdb"
      },
      "source": [
        "train = train.reshape(train.shape[0], train.shape[1],1)# X.reshape(samples, timesteps, features)\n",
        "validation = validation.reshape(validation.shape[0], validation.shape[1],1)# X.reshape(samples, timesteps, features)\n",
        "test = test.reshape(test.shape[0], test.shape[1],1)# X.reshape(samples, timesteps, features)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7L1QMiQzHdf"
      },
      "source": [
        "#train = train.T\n",
        "#validation = validation.T\n",
        "train.shape\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(labels_train)\n",
        "y_val = to_categorical(labels_validation)\n",
        "y_test = to_categorical(labels_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxoN6AdWOy_P"
      },
      "source": [
        "best_model_saved = ModelCheckpoint('/content/drive/My Drive/NLP_Dataset/models/best_acc_model.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
        "batch_size = 128\n",
        "model.fit(x=train,\n",
        "              y=y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=400,\n",
        "              verbose=1,\n",
        "              shuffle=True,\n",
        "              validation_data=(validation, y_val),\n",
        "              callbacks=[best_model_saved])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg_tMNYM0NDy"
      },
      "source": [
        "y_pred = model.predict(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vh5t3QS3kfb"
      },
      "source": [
        "type(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1UWbCQK1Kg1"
      },
      "source": [
        "example = 111\n",
        "index_of_maximum = np.argmax(y_pred[example])\n",
        "#y_pred[5]\n",
        "print('Classes probability', y_pred[example])\n",
        "print('Actual output', labels_test[example])\n",
        "print('Max probability',str(max(y_pred[example])))\n",
        "print('Class number',str(index_of_maximum))\n",
        "y_pred[example].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HDdoGSbKd97"
      },
      "source": [
        "labelencoder.inverse_transform(np.expand_dims(index_of_maximum, axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leENgNd3L3UE"
      },
      "source": [
        "sample = scaler.inverse_transform(np.squeeze(test[example]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1MM1QtNNo3V"
      },
      "source": [
        "Audio(sample,rate=fs,autoplay=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_A8kk3dP-G3"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZlP5I7qPlel"
      },
      "source": [
        "results = model.evaluate(train, y_train, batch_size=128)\n",
        "print('train loss, train acc:', results)\n",
        "results = model.evaluate(validation, y_val, batch_size=128)\n",
        "print('validation loss, validation acc:', results)\n",
        "results = model.evaluate(test, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X0bKVqEL4i5"
      },
      "source": [
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOxCWY8GBTkw"
      },
      "source": [
        "# **Model selection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY_AmUIPB75Q"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Fitting Random Forest Classification to the Training set\n",
        "classifier = RandomForestClassifier(n_estimators = 5, criterion = 'entropy', random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoPoTzt6wmFe"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "classifier.fit(train, labels_train)\n",
        "end = time.time()\n",
        "print(str(float(end-start)/60))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3Wbs4AKGwfa"
      },
      "source": [
        "y_val = classifier.predict(validation)\n",
        "y_train = classifier.predict(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAlwrNQ6_BEa"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "train_acc = accuracy_score(labels_train, y_train)\n",
        "validation_acc = accuracy_score(labels_validation, y_val)\n",
        "print('train acc is ' + str(train_acc))\n",
        "print('validation acc is ' + str(validation_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTWfoP2vHfLf"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "#rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring=’roc_auc’)\n",
        "#print(\"=== Confusion Matrix ===\")\n",
        "#print(confusion_matrix(labels_validation, y_val))\n",
        "#print('\\n')\n",
        "print(\"=== Classification Report train===\")\n",
        "print(classification_report(labels_train, y_train))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report val===\")\n",
        "print(classification_report(labels_validation, y_val))\n",
        "print('\\n')\n",
        "#print(\"=== All AUC Scores ===\")\n",
        "#print(rfc_cv_score)\n",
        "#print('\\n')\n",
        "#print(\"=== Mean AUC Score ===\")\n",
        "#print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymNQEN_g-AUm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV8vGpym5uh_"
      },
      "source": [
        "# **Silence elimnation (for developnment only)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVVDpUritB7T"
      },
      "source": [
        "pip install webrtcvad\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slpfsygv20HM"
      },
      "source": [
        "\n",
        "def silenceRemoval(sound_file, fs, mode = 3, chunk = 10):\n",
        "  vad = webrtcvad.Vad()\n",
        "  vad.set_mode(mode)\n",
        "  soundSamples = sound_file.shape[0]\n",
        "  chunkSamples = fs * chunk * (10**-3)\n",
        "  #duration = (soundSamples/fs) * 1000 # put it in ms\n",
        "  # make the duration divisible by the chunk\n",
        "  remain = soundSamples % chunkSamples\n",
        "  # padding my signal with (chunkSamples - remain)\n",
        "  if remain != 0:\n",
        "    zero_padding = int(chunkSamples - remain)\n",
        "    sound_file = np.pad(sound_file, (0,zero_padding), 'constant', constant_values=(0,0))\n",
        "  sound_file = sound_file.reshape(int(soundSamples / chunkSamples),-1)\n",
        "  deleted_rows = []\n",
        "  for i in range(sound_file.shape[0]):\n",
        "    frame = bytes(sound_file[i])\n",
        "    #print(vad.is_speech(frame, fs))\n",
        "    if not vad.is_speech(frame, fs):\n",
        "      deleted_rows.append(i)\n",
        "  sound_file = np.delete(sound_file, deleted_rows, axis=0)\n",
        "  sound_file = sound_file.reshape(sound_file.shape[0]*sound_file.shape[1],)\n",
        "  return sound_file, sound_file.shape[0]\n",
        "  \n",
        "  #return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKuzeYAYA78D"
      },
      "source": [
        "from scipy.io import wavfile\n",
        "sound_file = '/content/drive/My Drive/NLP_Dataset/audio/bed/4c4d2526_nohash_0.wav'\n",
        "fs, data = wavfile.read(sound_file)\n",
        "_, shape = silenceRemoval(data, fs)\n",
        "shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Eo8OeMlCnJM"
      },
      "source": [
        "from IPython.display import Audio\n",
        "Audio(data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaItrwQPCn8L"
      },
      "source": [
        "from IPython.display import Audio\n",
        "Audio(silenced_data,rate=fs,autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug6O44ZoEoeQ"
      },
      "source": [
        "# Augmentation Class 'Nwishy'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CueokMIR7Ksg"
      },
      "source": [
        "from scipy.fftpack import fft,ifft\n",
        "from scipy.signal import resample\n",
        "import numpy as np\n",
        "import math\n",
        "import random \n",
        "\n",
        "\n",
        "class DataAugForAudio():\n",
        "    \n",
        "    '''\n",
        "    time_shift function parameters:\n",
        "    \n",
        "      audio: choose required audio to shift\n",
        "      sampling_rate; sampling rate of the audio\n",
        "      direction: shift direction: left, right or both(is chosen randomly right or left) \n",
        "                                  and by default: left shift\n",
        "      max_shift: maximum shift of the audio in msec\n",
        "    '''\n",
        "    def time_shift(audio,sampling_rate,direction,max_shift):\n",
        "        coverage_maxlimit = (max_shift/1000) * sampling_rate\n",
        "        start = int(random.randint(0,coverage_maxlimit))\n",
        "        if direction == 'right':\n",
        "            start = -start\n",
        "        elif direction == 'both':\n",
        "            rand_direction = np.random.randint(0, 2)\n",
        "            '''\n",
        "            0: left direction\n",
        "            1: right direction\n",
        "            '''\n",
        "            if rand_direction == 1:\n",
        "                start = -start\n",
        "                \n",
        "        if start >= 0:\n",
        "            audio_shifted = np.r_[audio[start:], np.random.uniform(-0.001,0.001, start)]\n",
        "        else:\n",
        "            audio_shifted = np.r_[np.random.uniform(-0.001,0.001, -start), audio[:start]]\n",
        "        return audio_shifted\n",
        "    \n",
        "    \n",
        "    \n",
        "    '''\n",
        "    noise_injection function parameters:\n",
        "    \n",
        "      audio: choose required audio to shift\n",
        "      noise_factor: intensity of noise randomly chosen [e.x. n_f = np.round(random.uniform(0.01,0.09),3)] and 0.05 is the best choice \n",
        "      augmentated_zone: (tuple) range of audio duration that will be augmentated\n",
        "      \n",
        "      start = np.round(random.uniform(0,0.4),3) and 0.2 is the best choice\n",
        "      end = np.round(random.uniform(0.7,1),3) and 0.8 is the best choice\n",
        "      aug_zone=(start,end)\n",
        "      \n",
        "      background_noise: list of arrays of background noise wav file from kaggle or empty list if white gaussian noise by random.randn\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    def noise_injection(audio,noise_factor,augmented_zone,background_noise):\n",
        "        start_augmentation = augmented_zone[0]\n",
        "        end_augmentation = augmented_zone[1]\n",
        "        length = len(audio)\n",
        "        if background_noise == []:\n",
        "            noise = np.hstack((np.zeros(int(start_augmentation * length)),  noise_factor*np.amax(length)*np.random.randn(int((end_augmentation - start_augmentation)*length+1)) , np.zeros(length - int((end_augmentation * length)))))      \n",
        "            if len(noise) != len(audio):\n",
        "                noise = np.delete(noise,length-1)  \n",
        "            noisy_audio = audio + noise.astype(type(audio[0]))\n",
        "        else:\n",
        "            background_noise_sample =  background_noise[np.random.randint(len(background_noise))]\n",
        "            start_ = np.random.randint(background_noise_sample.shape[0]-length)\n",
        "            noise = background_noise_sample[start_ : start_+length]\n",
        "            noise_portion = noise[(int(start_augmentation * length)):(int((end_augmentation - start_augmentation)*length))+(int(start_augmentation * length))]\n",
        "            noise = np.hstack((np.zeros(int(start_augmentation * length)),  noise_portion , np.zeros(length - int((end_augmentation * length)))))\n",
        "            if len(noise) != len(audio):\n",
        "                noise = np.pad(noise,(0,length-len(noise)),'constant',constant_values=(0))\n",
        "            noisy_audio = audio* np.random.uniform(0.8, 1.2) + noise* np.random.uniform(0, 0.2)*noise_factor\n",
        "            noisy_audio = noisy_audio.astype(type(audio[0]))  \n",
        "        return noisy_audio\n",
        "\n",
        "\n",
        "    \n",
        "    '''\n",
        "    crop_audio function parameters:\n",
        "        \n",
        "        audio: choose required audio to crop\n",
        "        sampling_rate: sampling rate of the audio\n",
        "        start: factor for start time to crop the original audio and chosen randomly [e.x. start = random.uniform(0,0.3*duration_in_sec)]\n",
        "        stop: factor for stop time to crop the original audio and chosen randomly [e.x. stop = random.uniform(0.7*duration_in_sec,duration_in_sec)]\n",
        "        duration_in_sec: duration of the original audio in seconds [e.x. duration_in_sec = 1sec]\n",
        "        \n",
        "    '''\n",
        "    \n",
        "    def crop_audio(audio,sampling_rate,start,stop,duration_in_sec):\n",
        "        start = int(start*duration_in_sec*sampling_rate)\n",
        "        stop = int(stop*duration_in_sec*sampling_rate)\n",
        "        cropped_audio = audio[start:stop]\n",
        "        cropped_audio = resample(cropped_audio,sampling_rate)\n",
        "        cropped_audio = cropped_audio.astype(type(audio[0]))\n",
        "        return cropped_audio\n",
        "    \n",
        "    \n",
        "    \n",
        "    '''\n",
        "    fourier_transform function parameters:\n",
        "        audio: choose required audio to process\n",
        "        sampling_rate: sampling rate of the audio\n",
        "        shift_factor: shift in frequency domain (samples shift) and is chosen randomly. It could be positive or negative value\n",
        "                      [e.x. shift_factor = random.randint(-500,500)] and set the limits of randint function to values not greater\n",
        "                      than 2000 samples for example to make the audio clearly soundable (can be classified) \n",
        "    '''\n",
        "    \n",
        "    def fourier_transform(audio,sampling_rate,shift_factor):\n",
        "        audio_FFT = fft(audio)\n",
        "        rolled_audio_FFT = np.roll(audio_FFT,shift_factor)\n",
        "        if shift_factor > 0:\n",
        "            rolled_audio_FFT = np.hstack((np.zeros(shift_factor),rolled_audio_FFT[shift_factor:]))\n",
        "        else:\n",
        "            rolled_audio_FFT = np.hstack((rolled_audio_FFT[:len(rolled_audio_FFT)+shift_factor],np.zeros(-shift_factor)))\n",
        "        \n",
        "        shifted_audio_IFFT = ifft(rolled_audio_FFT) \n",
        "        shifted_audio_IFFT = shifted_audio_IFFT.astype(type(audio[0]))\n",
        "        return shifted_audio_IFFT\n",
        "    \n",
        "    \n",
        "    '''\n",
        "    pitch_shift function depends on 2 sub-functions which are createFrames that stretches the original audio and fusionFrames that\n",
        "    compresses the processing audio. The parameters of this function are:\n",
        "        audio: choose required audio to process\n",
        "        sampling_rate: sampling rate of the audio\n",
        "        window_size: depends on sampling frequency, must be number divisible by 2 and chosen after some trys to get a good quality \n",
        "        overlap_factor: the overlapping that happens between the current frame and next one and chosen randomly\n",
        "                        and the best value is 75% overlapping. this factor determines the size of the hop which is always less than\n",
        "                        window size.\n",
        "        n_of_semitones: number of shifting steps and should be in range of [-4:4] for the quality of the audio\n",
        "        \n",
        "        This function idea is taken from matlab code and the authors are: Laurier Demers, Francois Grondin, Arash Vakili. \n",
        "        \n",
        "        github link:                 \n",
        "    '''\n",
        "     \n",
        "    \n",
        "    def pitch_shift(audio,sampling_rate,window_size,overlap_factor,n_of_semitones):\n",
        "        \n",
        "        def createFrames(audio,hop,window_size):\n",
        "            length =len(audio)\n",
        "            n_slices = math.floor((length - window_size) / hop)\n",
        "            audio = audio[0:(n_slices*hop+window_size)]\n",
        "            v_frames = np.zeros((math.floor(length/hop),window_size)) \n",
        "            for index in range (0,n_slices):\n",
        "                 index_time_start = (index)*hop +1\n",
        "                 index_time_end = (index)*hop + window_size\n",
        "                 v_frames[index][:] = audio[index_time_start-1 : index_time_end]\n",
        "            return v_frames , n_slices \n",
        "        \n",
        "        def fusionFrames(frames_matrix, hop):\n",
        "            numberFrames = frames_matrix.shape[0]\n",
        "            sizeFrames = frames_matrix.shape[1]\n",
        "            vectorTime = np.zeros(numberFrames*hop-hop+sizeFrames)\n",
        "            timeIndex = 0\n",
        "            for index in range(0,numberFrames):\n",
        "                 vectorTime[timeIndex:timeIndex+sizeFrames] = vectorTime[timeIndex:timeIndex+sizeFrames] + np.transpose(frames_matrix[index][:])\n",
        "                 timeIndex = timeIndex + hop\n",
        "            return vectorTime\n",
        "        \n",
        "        if n_of_semitones != 0:\n",
        "            win_size = window_size\n",
        "            hop = int(win_size*overlap_factor)\n",
        "            alpha = 2**(n_of_semitones/12)\n",
        "            hop_out = round(alpha*hop)\n",
        "            window_arr = np.blackman(win_size*2+1)\n",
        "            window_arr = window_arr[2::2]\n",
        "            original_audio = audio\n",
        "            original_audio_new = np.hstack(((np.zeros(hop*3)),original_audio))\n",
        "            framed_audio,number_frames_in = createFrames(original_audio_new,hop,win_size)\n",
        "            number_frames_out = number_frames_in\n",
        "            out = np.zeros((number_frames_out,win_size))\n",
        "            phase_cumulative = np.zeros((1,framed_audio.shape[1]))\n",
        "            previous_phase = np.zeros((1,framed_audio.shape[1]))\n",
        "\n",
        "            for index in range (0,number_frames_in):\n",
        "                current_frame = framed_audio[index][:]\n",
        "                current_frame_windowed = current_frame* np.transpose(window_arr) / math.sqrt(((win_size/hop)/2))\n",
        "                current_frame_windowed_FFT = fft(current_frame_windowed)\n",
        "                mag_frame = abs(current_frame_windowed_FFT)\n",
        "                phase_frame = np.angle(current_frame_windowed_FFT)\n",
        "                deltaPhi = phase_frame - previous_phase\n",
        "                previous_phase = phase_frame\n",
        "                deltaPhiPrime = deltaPhi - hop * 2*math.pi*np.arange(0,win_size)/win_size\n",
        "                deltaPhiPrimeMod = ((deltaPhiPrime+math.pi) % (2*math.pi)) - (math.pi)\n",
        "                trueFreq = (2*math.pi*np.arange(0,win_size)/win_size) + (deltaPhiPrimeMod/hop)\n",
        "                phase_cumulative = phase_cumulative + hop_out * trueFreq\n",
        "                outputMag = mag_frame\n",
        "                outputFrame = np.real(ifft(outputMag * np.exp(1j*phase_cumulative)))\n",
        "                out[index][:] = (outputFrame * np.transpose(window_arr)) / math.sqrt(((win_size/hop_out)/2))\n",
        "    \n",
        "            outputTimeStretched = fusionFrames(out,hop_out)\n",
        "            outputTime = resample(outputTimeStretched,int(len(outputTimeStretched)/alpha))\n",
        "            outputVector = resample(outputTime,sampling_rate)\n",
        "            outputVector = outputVector.astype(type(audio[0]))   \n",
        "            return outputVector\n",
        "        \n",
        "        else:\n",
        "            return audio\n",
        "    \n",
        "    '''\n",
        "    speed_change function parameters:\n",
        "        \n",
        "    '''\n",
        "\n",
        "    def speed_change(audio,factor_1,factor_2,zone_1,zone_2):\n",
        "        \n",
        "        def speedx(sound_array, factor):\n",
        "        ##speed sound by factor\n",
        "            indices = np.round( np.arange(0, len(sound_array), factor) )\n",
        "            indices = indices[indices < len(sound_array)].astype(int)\n",
        "            return sound_array[indices.astype(int)]\n",
        "        \n",
        "        data_s1 = math.ceil(zone_1 * len(audio)) ##get the size of the first zone\n",
        "        data_s2 = math.ceil(zone_2 * len(audio)) ##get the size of the second zone\n",
        "        if data_s1 < data_s2 :\n",
        "            data_1 = speedx(audio[0:data_s1], factor_1)  ##speed the first zone by factor_1\n",
        "            data_2 = audio[data_s1:data_s2]\n",
        "            data_3 = speedx(audio[data_s2:] , factor_2)  ##speed the third zone by factor_2\n",
        "        if data_s1 >= data_s2 :\n",
        "            data_1 = speedx(audio[0:data_s2] , factor_1)\n",
        "            data_2 = audio[data_s2:data_s1]\n",
        "            data_3 = speedx(audio[data_s1:], factor_2)\n",
        "        audio_f = np.concatenate((data_1,data_2,data_3))  ##concatenate the 3 zones\n",
        "        audio_f = resample(audio_f,audio.shape[0])\n",
        "        audio_f = audio_f.astype(type(audio[0]))\n",
        "        return audio_f\n",
        "    \n",
        "    \n",
        "    '''\n",
        "    mask_filter function parameters:\n",
        "        \n",
        "    '''\n",
        "\n",
        "    def mask(audio,mask_with_noise,zone_1,zone_2):\n",
        "        data_s1 = math.ceil(zone_1 * len(audio)) ##get the size of the first zone\n",
        "        data_s2 = math.ceil(zone_2 * len(audio)) ##get the size of the second zone\n",
        "        if mask_with_noise == True :\n",
        "            if data_s1 < data_s2 :\n",
        "                data_1 = audio[0:data_s1] \n",
        "                data_2 = 100*np.random.normal(0,1,data_s2-data_s1)  ##if mask_with_noise == True replace the zone by noise\n",
        "                data_3 = audio[data_s2:] \n",
        "            if data_s1 >= data_s2 :\n",
        "                data_1 = audio[0:data_s2] \n",
        "                data_2 = 100*np.random.normal(0,1,data_s1-data_s2)\n",
        "                data_3 = audio[data_s1:]\n",
        "        if mask_with_noise == False :\n",
        "            if data_s1 < data_s2 :\n",
        "                data_1 = audio[0:data_s1] \n",
        "                data_2 = np.zeros(data_s2-data_s1)\n",
        "                data_3 = audio[data_s2:] \n",
        "            if data_s1 >= data_s2 :\n",
        "                data_1 = audio[0:data_s2] \n",
        "                data_2 = np.zeros(data_s1-data_s2)  ##if mask_with_noise == False replace the noise by zeros\n",
        "                data_3 = audio[data_s1:]\n",
        "        audio_f = np.concatenate((data_1,data_2,data_3))\n",
        "        return audio_f\n",
        "    \n",
        "    \n",
        "    '''\n",
        "    change_volume function parameters:\n",
        "        \n",
        "    '''\n",
        "\n",
        "\n",
        "    def change_volume(audio,factor_1,factor_2,zone_1,zone_2):\n",
        "        data_s1 = math.ceil(zone_1 * len(audio))  ##get the size of the first zone\n",
        "        data_s2 = math.ceil(zone_2 * len(audio))  ##get the size of the second zone\n",
        "        if data_s1 < data_s2 :\n",
        "            data_1 = audio[0:data_s1] * factor_1 ##increase the volume (first zone) by factor_1\n",
        "            data_2 = audio[data_s1:data_s2]\n",
        "            data_3 = audio[data_s2:] * factor_2  ##increase the volume (second zone) by factor_2\n",
        "        if data_s1 >= data_s2 :\n",
        "            data_1 = audio[0:data_s2] * factor_1\n",
        "            data_2 = audio[data_s2:data_s1]\n",
        "            data_3 = audio[data_s1:] * factor_2\n",
        "        audio_f = np.concatenate((data_1,data_2,data_3))\n",
        "        return audio_f\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II6EIOTIFJWw"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig7V6LSkHk0L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}